[
  {
    "label": "Expectation",
    "type": "Class",
    "description": "Is it some action/process/ that could happen (belief).",
    "provocation": "Who are the key actors shaping contemporary societal expectations of AI?",
    "references": "\"... Expectations can be defined as statements that say something about the future (Borup et al., 2006, van Lente, 2012). A range of actors, and both formal and informal mechanisms, shape expectations (Pollock and Williams, 2016; van Lente, 2012). Formal mechanisms include foresight and research prioritisation exercises, which are deployed by governments, consultancy firms and companies to rationalise future innovation agendas and investment. Informal expectations are ‘images, statements and prophecies’ (van Lente, 2012: 772) which circulate through social networks, the media, conferences and meetings. Some informal images and statements are provided by experts. Non-experts can also play a role in shaping expectations via the media and other activities. In the construction of expectations, a range of actors draw from, and add to, the repertoire of visions that create the innovation dynamic around a technology....Collectively shared expectations can have a significant influence. Previous studies have identified three ‘forces’ of expectations: they raise attention and legitimate investment, they help to coordinate networks of companies and research institutions, and they provide heuristic guidance and direction to research and innovation activities (Van Lente, 2012: 773–774). Expectations can be said to be ‘performative’ in the sense that they ‘do’ something, and may prompt certain social actions...\" (Kerr et al., 2020)"
  },
  {
    "label": "Ethical Assessment",
    "type": "Class",
    "description": "Ethical assessment involves evaluating actions, decisions, or policies to determine their moral implications and adherence to ethical principles, ensuring responsible and conscientious conduct in various domains.",
    "provocation": "At what stage of ML development did they assess the societal or ethical impacts of the AI system?",
    "references": "(To be updated)"
  },
  {
    "label": "Edtech Platform",
    "type": "Class",
    "description": "An edtech platform refers to a digital environment or software system designed to facilitate teaching, learning, and educational activities over the internet.",
    "provocation": "What role do edtech platforms play in the larger discussion on what it means to teach and learn?",
    "references": "\"...Similar to questions of digital in/exclusion, the spectre of digital data and datafication has been a prominent feature of education for some time. Nevertheless, the continued adoption of artificial intelligence into mainstream education throughout the 2020s will initiate datafication on an unprecedented scale. All these disparate forms of artificial intelligence (from deep learning to adversarial networks), are undeniably hungry for data. Leading the charge to extract data from educational set-tings will be digital platform providers for whom user data is their most valuable commodity. As with social media platforms in the 2000s, educational platform providers will be working toexpand the scope of their walled gardens’to encompass as many user practices as possible, leadingtoclassrooms on platformsrather thanplatforms in classrooms. Artificial intelligence will increasinglybecome the engine of education, and student data the fuel. Critical EdTech researchers therefore need to pay close attention to the fate of these educational platform providers and to the ecosystems of nested platforms and services hidden by the everyday interfaces that students and teachers workwith. Will educational platforms act as data brokers for the advanced AI backends delivered by com-peting US and Chinese giants? Will platform providers be bought up, or simply be replaced by ver-sions from these larger conglomerates themselves?...\" (Selwyn et al., 2020)."
  },
  {
    "label": "Academic Funding",
    "type": "Class",
    "description": "Funding received from an institute of higher education. This type of funding often has a strong research component.",
    "provocation": "How do the universities' funding incentives try to influence the direction of the research?  What is the impact of institutionalised funding arrangements on the production of scientific knowledge, i.e., on research practices and the knowledge produced by these practices? (Gläser & Velarde, 2018)",
    "references": "Funding regimes directly impact how a research problem is framed. This link has been noted in the existing literature, although sporadically. A relational ethical framework enables researchers/users of research-led AI systems to critically reflect and openly debate how funding regimes influenced their research design, how existing funding systems hope to extract economic value from \"useful knowledge\", and an efficient AI system. Do they endorse this influence? If not, how do they find ways to work around it? For instance,  \"A second, related trend is that research funding is increasingly used as a means to exercise authority over the production of scientific knowledge (Whitley et al. 2010). Policymakers and funding agencies attempt to influence the conduct and content of research through the modification of funding arrangements: They try to exercise control over the direction of research by incorporating, for instance, public policy goals in funding programmes (Furman et al. 2012), introducing incentives to collaborate with industry and to commercialise funding (Swan et al. 2010), and creating mission-based research organisations (Cruz-Castro et al. 2012)\" (Gläser & Velarde, 2018).  Also, it's important to note that \"recently, especially in countries such as in the USA, the United Kingdom and Australia, market forces and government simulated market actions (via performance-based funding systems) have significantly influenced the behaviour of universities (Massy, 1996)\"."
  },
  {
    "label": "Academic Institution",
    "type": "Class",
    "description": "Refers to Institutes of higher education such as universities, colleges, research institutes or schools.",
    "provocation": "Is the academic institute inclusive and accessible or is it exclusionary and only caters to a certain elite? \nWho is set to gain the most from the research project? \nDid the culture of the academic institute influence the design of the AI system and the values encoded therein?",
    "references": "\"...Existing research has noted that 'Organizational context plays a role in what comes to count as knowledge' (Gumport & Snydman, 2002). Given the curatorial role that academic institutions play vis-à-vis classifying and establishing categories of expertise and knowledge worth knowing' which in turn 'influences how money and resources are distributed', an exploration of this interplay and 'interdependencies between organizational context and what counts as knowledge' (Gumport & Snydman, 2002) could lead to worthile insights into what is ethical AI? In the contemporary, 'universities are becoming increasingly dependent upon a pool of workers employed to teach and conduct research on precarious and unfavourable contracts. This enables established academics to concentrate on activities aimed at hitting targets and advancing strategic objectives prioritised by managers'...\" (Mason & Megoran, 2021)."
  },
  {
    "label": "Achieve Sdg Goals",
    "type": "Class",
    "description": "When the design of an AI system is explicitly driven by the motivation to contribute to the UN's sustainable development goals.",
    "provocation": "What motivated the team to align the AI design with SDGs?",
    "references": "AI's alignment with SDGs promotes a normative framework. This alignment is often promoted to avoid scenarios where AI behind social good projects \"may have been designed for the “good” but, in practice, it could end up going “bad.”(Astobiza et al., 2021). However, SDGs are not innocent and some have argued that SDGs work to \"naturalize and consolidates the existing status quo: a status quo that has created (and continues to perpetuate) the global problems that the agenda aims to solve.\" (Telleria & Garcia-Arias, 2022). or that SDG should be seen as a local paradigm and not a global one, and that this paradigm becomes problematic when applied homogeneously everywhere\" (Vásquez-Fernández & Ahenakew Pii Tai Poo Taa, 2020)"
  },
  {
    "label": "Action Research",
    "type": "Class",
    "description": "A qualitative, post-positivist research approach that is conducted with the intention to transform or intervene for emancipatory purposes. It's meant to be cyclical, collaborative and iterative.",
    "provocation": "\"What sorts of problems have the investigations addressed? What aspects or dimensions of practices, understandings and situations did they problematise? In what way did they make these things problematic? Did they problematise things subjectively, from the perspective of particular practitioners or professions, or did they problematise them intersubjectively, opening a communicative space for conversation between co-participants in practices and settings?\" (Kemmis, 2006)",
    "references": "\"While action research begins with an emancipatory ideal, it  assumes \"a reality which can be uncovered and then altered in some way or improved upon\"\" which demands that the team and the designers critically reflect upon the kye question: \"where our ideas of what counts as ‘improvement’\ncome from\"\" (Brown & Jones, 2001). It has also been noted that more recently action research has lost its critical edge."
  },
  {
    "label": "Activist",
    "type": "Class",
    "description": "A type of user who is actively involved in mobilizing a community for a social or political cause.",
    "provocation": "How did the design of an AI system involve the activists: as mere grassroots consultants or key stakeholders that could influence the design?",
    "references": "\"...figure of an activist is itself a site of contestation and confusion. Activists are often read as the most agentive of all subjects – those that seek to challenge the existing norms and model alternative forms of life\". Given this contestation, it is important to \"hold together this figure’s meaningful promises that animate the political imagination for desiring a different future in some places ... and the fruitful abandonment of the figure in order to be able to desire a different future in other sites...\" (Kurtović & Sargsyan, 2019)"
  },
  {
    "label": "Actor",
    "type": "Class",
    "description": "Any human or nonhuman entity that is capable of action and influencing the network.",
    "provocation": "What do different actors do to the system and how do they come to act?",
    "references": "We understand 'actor' as in Latour (2005): \"...An ‘actor’ in the hyphenated expression actor-network is not the source of an action but the moving target of a vast array of entities swarming toward it... To use the word ‘actor’ means that it’s never clear who and what is acting when we act since an actor on stage is never alone in acting... Action is not done under the full control of consciousness; action should rather be felt as a node, a knot, and a conglomerate of many surprising sets of agencies that have to be slowly disentangled...\". To identify both human and non-humans as actors is to draw \"attention to the distributed and relational dimensions of the agential capacities that are generated in and through humans’ encounters with nonhumans...\" (Lupton, 2020)"
  },
  {
    "label": "Affordance",
    "type": "Class",
    "description": "That aspect of a socio-technical system that offers possibilities for action. These are either intended or unintended possibilities.",
    "provocation": "How does an AI system alter human perception (Döbler & Bartnik, 2022)? How does it make us relate to the world in different ways?",
    "references": "\"...Technology in its use actively shapes human perception and thus influences which affordances can emerge and are realized in the human form of life. Hence, technologies are part of the human ecological niche; the way we live. In other words: By influencing the perception of affordances, technology influences which patterns of behaviour emerge from these possibilities, become widely available, and eventually manifest themselves in concrete practice. What is important here is that adopting these behavioural patterns is not just a matter of social persuasion and convention but begins much earlier: In the mediated perception and notion of what is possible in the first place...Technologies help to determine how people act, so that it is not only people but also things who give answers to the classical moral question, ‘How to live?...’” (Döbler & Bartnik, 2022)"
  },
  {
    "label": "Ai4sg",
    "type": "Class",
    "description": "Refers to ideas/discourse that emphasise upon the use, development and deployment of AI systems for social good.",
    "provocation": "What do the actors involved mean by social good? How did they arrive at their definition? Did they consider the normative values underpinning the definition of social good? Who gets to define what is social good?",
    "references": "AI4SG is often conflated to mean “AI4SG = AI×SDGs” with  \"the assumption that “SDGs offer clear, well defined and shareable boundaries to identify positively what is socially good AI” and that “SDGs are internationally agreed on goals for development and have begun informing relevant policies worldwide, so they raise fewer questions about relativity and cultural dependency of values” [25:112]. Such framing has some glaring shortcomings that Cowls et al. choose to ignore. UN SDGs, like most United Nations consensus exercises, are not legally binding nor represent goals and principles that political groups intra-nationally or trans-nationally agree upon. Secondly, SDGs, as Telleria and Garcia-Arias [95:15] argue, is an “empty signifier that keeps disparate and even contradictory demands united”. It does this by constructing “a fantasmatic explanation of international development and sustainability issues that conceals the antagonistic dimension of social, political and economic issues” [95:15]. In a later special issue introduction edited by Cowls, Cowls notes contrary to such a straightforward and simple solution that “The contributions make clear that neither ‘AI’ nor ‘social good’ should be thought of as uncontested or incontestable terms, and we should remain wary of the twin dangers of unjustified hype and unseen harm arising from the continued growth of interest in, and application of, AI” [24:54].\" ( Arora & Sarkar, 2023)"
  },
  {
    "label": "Ai System",
    "type": "Class",
    "description": "A socio-technical system that uses some aspect of artificial intelligence to complete a task or achieve a goal..",
    "provocation": "Does the social problem need an AI as a solution? How is AI produced as part of a social imaginary?",
    "references": "(To be updated)"
  },
  {
    "label": "Angel and Venture Investment",
    "type": "Class",
    "description": "Angel investment involves personal investment made by high-net-worth individuals or a group of individuals either informally or through social networks. These investors invest their own money to provide early-stage funding in exchange for financial and non-financial returns. They sometimes play an active role in the business either as advisors or members of the board of directors. Venture capital firms invest in startup companies and emerging businesses that are focused on developing and advancing artificial intelligence technologies, products, or services.",
    "provocation": "What monetary or non-monetary value did the investor see in an AI system? Does the involvement influence the design of the AI system?",
    "references": "\"...Grounded in agency theory, our findings suggest that strategic readiness for funding and passion matter more to angel investors, that economic potential matters more to VCs, and that both investor types place similar weights on the specific human capital of entrepreneurs.\" \"In addition, angel investors are concerned about the entrepreneur’s behavior once they decide to invest (Kelly and Hay 2003). In other words, they are likely to use behaviororiented mechanisms to control the entrepreneur after investing. Many angel investors, unlike VCs, want to be informed about the daily operation of the venture and to work with the entrepreneur closely,such as visiting the venture or conducting recurring meetings with entrepreneurs (Landstro¨m 1998; Prowse 1998; Van Osnabrugge and Robinson 2000; Wright and Robbie 1998). Many angel investors also consider themselves co-entrepreneurs of the invested ventures and act like an entrepreneur (Landstro¨m 1998). The concept of coentrepreneurs not only aligns the goals of the angel investors with the entrepreneur’s goal but also mitigates the issue of information asymmetries through closely working with the entrepreneur...\" (Hsu et al., 2014)"
  },
  {
    "label": "Appropriate Scale",
    "type": "Class",
    "description": "An ethical parameter that is conscious of the constructed nature of the scales ie.e scales such as local, global, national etc are not given but constructed.",
    "provocation": "How is the world re/de/scaled in the design of an AI system?",
    "references": "\"...This is an ethical principle borrowed from recent debates in geography that refuse to define it as a static container in which actors, entities or subjects simply find themselves but instead as that which is constantly made and remade and brought into being, evaded, practiced and at times becomes a site for political contestation (Herod, 2011). Development of AI systems often feteshize scale \"when scale is considered to exist independently of the social or natural relations and processes which create it\". Thus, to scale up an AI system is often presented as a marker of success while ignoring the ethico-political consequences of the same. Though it should be noted that there's not yet enough work on this aspect of AI systems and how they rescale the world. It might be worthwhile to remember that an \"understanding the world as scaled provides us with a sense of size (as when “the local” is seen as smaller than “the global”), of power relationships (as when “the global” is thought to be undermining the influence of other scales such as “the national” and “the local”), and, often, of hierarchy (as when we consider the global scale more important than scales such as the national)...\" (Herod 2011)."
  },
  {
    "label": "Artistic",
    "type": "Class",
    "description": "A design motive that foregrounds the aesthetic considerations over and above everything else in its design of an AI system.",
    "provocation": "What kind of a relation between art and AI is being imagined in the design of the AI system?",
    "references": "\"Mobilising the tools of imagination, visualisation, narrative, metaphor, parable and irony, artists can perhaps begin by blowing some much-needed cool air on the heat and hype around AI currently emitting from tech companies\".  The emphasis here is on relation rather than purpose and suspicion concerning \" bombastic claims with regard to art’s efficacy in solving social ills, ‘empowering’ communities or ‘causing’ change by revealing injustice. This is not to say that art should not ever attempt to do the latter, only that artists themselves could perhaps curb somewhat their own exuberant beliefs and pronouncements. The efficacy of art that engages with AI lies perhaps first and foremost in its ability to redraft the conceptual and discursive boundaries of human perception, human value and human cultural practice while drawing us as its human recipients into the recognition of our becoming (with) machines. such art can also make our human intelligence look inherently artificial--\" (Zylinska, 2020)"
  },
  {
    "label": "Bias",
    "type": "Class",
    "description": "When the results of an AI system are systemically prejudiced due to both accounted or unaccounted assumptions in the machine learning process.",
    "provocation": "Would debiasing the AI system solve the problem of potential discrimination?",
    "references": "\"...The first type of bias in the typology that I propose is purely technical bias, which I define quite broadly so that it includes any kind of technical or conceptual mismeasurement and misconception. A deviation exists here between what one wants to depict or measure and what is depicted or measured. However, this deviation is not based on an underlying structural inequality. The second type of data bias I call socio-technical bias. In this case there is a discrepancy between what is to be represented and what is being represented, and this discrepancy is a direct result of structural inequalities. This includes cases where disadvantaged groups are less visible, overly visible or wrongly depicted because of the way data is produced. Several cases of data bias have been discussed in the media and beyond, as in Angwin et al. (2016) and Criado-Perez (2019). The third type is societal bias. The crucial aspect here is that societal bias is not a deviation of the datafication of a phenomenon from reality—acknowledging that reality is, obviously, a highly contested concept that always follows a normative decision. According to the proposed typology, societal bias arises when structural inequalities are reflected in the respective data, albeit correctly. The underlying data of an algorithmic system depicts—in a correct way—that society structurally discriminates against certain groups...\" (Lopez, 2021)."
  },
  {
    "label": "Bigdata Analysis",
    "type": "Class",
    "description": "A method of data analysis that detects trends, patterns, and correlations in large amounts of data.",
    "provocation": "How does data come to constitute/enact reality? How was it curated and what does it do?",
    "references": "\"...It is now generally understood that data has become a major object of economic, political, and social investment for governing subjects. This development has been captured by the term Big Data to mark a departure from conventional forms of data and statistical knowledge. While first coined by industry, Big Data has come to have different meanings and uses...Yet, data remains a key matter of concern as both the product and condition of computation and analytics\". Also, \"data is not an already given artefact that exists (which then needs to be mined, analysed, brokered) but an object of investment (in the broadest sense) that is produced by the competitive struggles of professionals who claim stakes in its meaning and functioning...\" (Ruppert et al., 2017)."
  },
  {
    "label": "Borrower",
    "type": "Class",
    "description": "A type of user that receives money, assets, or services on credit from another individual, organization or the bank.",
    "provocation": "How do AI-based lending systems impact resource allocation? How do borrowers understand, learn/struggle to ‘make themselves up’ in response to the market’s new algorithmic ways of seeing (via financial objects such as credit score)?",
    "references": "\"...Despite the role of the credit score as a ‘neutral … referent’ (Ashton & Christophers, 2015, p. 191), whose acceptance as a true measure of default risk is integral to the ‘efficient’ operation of consumer credit markets, the data and algorithms used to calculate credit score are embedded in cultures and practices of judgement and discrimination that are far from neutral and render the facticity of the score a fiction. On the one hand, to minimize credit rationing (Stiglitz & Weiss, 1981) market participants must (to some degree) indulge the fiction that there exists a neutral metric capable of accurately representing the risk of lending to particular persons (i.e. credit score). On the other hand, credit score, as we will see, has many blind spots, biases (e.g. home-rental payments are not reported, but mortgage payments are), and ‘off-label’ (ab)uses (see Rona-Tas, 2017). Further, it is often selectively applied and used to target vulnerable populations with predatory financial products, and, as Pasquale contends, it ‘launder[s] past practices of discrimination into a black-boxed score’ (Pasquale quoted in McClanahan, 2016, p. 72)...\" (Kear, 2017)."
  },
  {
    "label": "Care Ethic",
    "type": "Class",
    "description": "A type of ethical framework that prioritizes the relationship of care especially with those who are vulnerable.",
    "provocation": "Is the care ethic morally imposed from above or carefully built bottom-up? How does the design account for social stratifications that divide society into caregivers and care receivers?",
    "references": "\"..Thinking care as inseparably a vital affective state, an ethical obligation and a practical labour has been from very early on at the heart of feminist social sciences and political theory; an endeavour that has become more visible with increased interest in the ‘ethics of care’.While it is fair to say that care has been and remains an essential feature of transformative feminist politics and alternative forms of organizing, ‘caring’ is also commonplace in everyday moralizations: for example, companies compete to show how much they care, buying recycled toilet paper shows that we care, and caring for the self is a pervasive order of biopolitical morality.\nYet care is too important a notion to reduce it to hegemonic ethics (Puig de\nla Bellacasa, 2010; Latimer and Puig de la Bellacasa, forthcoming).Thinking in\nthe world involves acknowledging our own involvements in perpetuating\ndominant values, rather than retreating into the secure position of an enlightened outsider who knows better. In this spirit, my intention here is not to stage\na confrontation with mainstream notions of care, but rather, following feminist\nprecursor work such as that of Hilary Rose (1983, 1994), to articulate a nonidealized vision of care that is meaningful for matters of thinking and knowing...\" (De La Bellacasa, 2012)"
  },
  {
    "label": "Case Study",
    "type": "Class",
    "description": "A type of qualitative and/or quantitative research method that engages in an indepth study of one or small number of individuals, groups or events.",
    "provocation": "Does the use of this method narrate new stories or design fictions concerning AI?",
    "references": "...AI fields have a tendency to \"prioritize solutions before a complex or “wicked” problem space has been adequately explored (Blythe et al., 2016)\"(Muller & Liao, n.d.). In contrast, case study method can provide a \"richness and depth to the description and analysis of the micro events and larger social structures that constitute social life...\" (Feagin et al., 2016)."
  },
  {
    "label": "Case Worker",
    "type": "Class",
    "description": "A case worker is a professional who assesses, advocates, and provides support to individuals or families in need, coordinating resources and services to address their specific circumstances and improve their well-being.",
    "provocation": "How is the case worker's access to information and relevant data designed in design of the AI system?",
    "references": "\"...A key contributing factor is that throughout the process call workers continued to have access to not only the referral calls but also the administrative data system. This provided a different view of the case than what was being pulled into the risk score calculation. In particular, even when inputs related to past child welfare history were being miscalculated in real time, workers would still have access to the correct information in the data system. In addition to the role of having access to the raw features, and having the time to inspect these, it is particularly important to highlight that call workers had been previously trained to make decisions without the aid of a risk assessment score. Therefore, they had experience in parsing and interpreting the raw data. A question that arises is whether this previous experience had an important role, and whether the same behavior can be expected from call workers who start working after the deployment of the tool...Secondly, the risk tool provides workers only with a score, and does not ‘explain’ its predictions, nor does it display values of any of the features involved in the score calculation. If this additional information had been provided, it is possible that the glitch would have been detected by workers. However, it is also possible that this distillation of the data would have been trusted by workers, who would in turn have been dissuaded from examining the original data...\" (De-Arteaga et al., 2020).\""
  },
  {
    "label": "Censorship",
    "type": "Class",
    "description": "A type of risk where either an indiviual or a group is not allowed to express an opinion or share information.",
    "provocation": "Does the AI system control how information is disseminated?",
    "references": "Censorship harms are predominantly studied in the context of platforms and recommender systems. \"The need to examine the power of social platforms through algorithmic censorship and the structural conditions this creates arises, in part, from the political nature of new technologies. As Winner argued in 1980, “technological innovations are similar to legislative acts or political foundings that establish a framework for public order that will endure over many generations … the same careful attention one would give to the rules, roles, and relationships of politics must also be given to such things as the building of highways, the creation of television networks, and the tailoring of seemingly insignificant features on new machines” (Winner 1980: 43). The design, deployment, and use of new technologies can have lasting effects on society, setting us on paths that in many cases are difficult to depart from or reverse. Even ancient and seemingly mundane infrastructural technologies such as bridges, Winner showed us, can be intentionally designed in such a way as to permit or exclude certain behaviours—and, indeed certain groups of people—and produce long-lasting political effects\" (Cobbe, 2021)."
  },
  {
    "label": "Co Design",
    "type": "Class",
    "description": "A type of research method where knowledge/or an artefact is coconstructed with the individual, group or community that has stakes in the knowledge/artefact being produced.",
    "provocation": "How did the co-design practice unfold?",
    "references": "\"...Indeed, the links between feminist theory and participatory/co-design processes have been well acknowledged and outlined extensively in the field.\nHowever, recent articles have also demonstrated that co-design in the public sector is vulnerable to co-option (e.g. Blomkamp, 2018). As one countermeasure, there are calls for co-design practitioners to be more reflexive about how they enact design methods and attune to the relational aspects of participatory processes (e.g. Light & Akama, 2012). Rather than outlining what feminist co-design practitioners should be doing (in terms of frameworks or universal principles)\" it is important to explore \"how feminist co-design practice unfolds and develops across applied project situations...\"(Korsmeyer, 2022)."
  },
  {
    "label": "Coaching Centre",
    "type": "Class",
    "description": "Private institutes that offer educational or training services outside of the schol system.",
    "provocation": "Do the coaching institutes explicitly specific how they use AI to improve learning? Do the parents and students understand for what purposes the AI is being used and how? Do the parents/students have an option to opt out of the AI services and still recieve mentoring services?",
    "references": "Private tuition and coaching centres for competitive exams is a \"billion dollar industry\" in developing countries such as India (Kaur, 2020) There's as yet no dedicated work on how private coaching centres use AI. However, it's possible that they might integrate AI into their mentoring or marketing strategies in the near future...."
  },
  {
    "label": "Community Philanthropy",
    "type": "Class",
    "description": "A type of funding where members of the community pool their personal resources to fund an enterprise or a socio-technical system that is expected to provide mutual benefits.",
    "provocation": "How is the 'community' being defined? Does it involve the most vulnerable in the community?",
    "references": "\"...In 2016, the first Global Summit on Community Philanthropy marked an important moment in the emergence of a field. With it emerged the campaigning hashtag, #ShiftThePower. The summit, held in Johannesburg, South Africa, brought together some 350 people from more than 60 different countries.Footnote2 Its aim was not only to recognise and celebrate a growing global community philanthropy movement, but also to invite a broader range of people and organisations working in different parts of the development system to join forces and work together towards a new paradigm of people-led development. The past decade has seen the global community philanthropy movement become more visible, vocal, and organised (see Gilbert Citation2018; Hodgson and Knight Citation2016; Hodgson and Pond Citation2018). It includes new kinds of organisations and networks that have surfaced from the ground up, which all emphasise the role of local community resources in challenging conventional power dynamics and in producing qualitatively different outcomes. While money is important in community philanthropy, it is not central: instead, value is placed on generosity, trust, and solidarity, and on numbers and quality of relationships between people, communities, and institutions.\nThis article explores the emerging role and power of community philanthropy as a source of both alternative practice which seeks to activate and unlock community energies and assets, and as a rebuke of top-down mainstream development approaches. It assesses its potential to help shape broader efforts to move towards a more equitable and locally rooted system for people-led development...\" (Hodgson, 2020).\""
  },
  {
    "label": "Corporate Funding",
    "type": "Class",
    "description": "A type of funding where a company funds an AI system in exchange of deriving future benefits from the system.",
    "provocation": "Why is a corporate entity invested in the AI system for social good?",
    "references": "...\"Concerns about ‘ethicswashing’, ‘ethics-shopping’ and ‘ethics theater’ are repeatedly validated by examples of companies seeking to water down research that brings scrutiny to inherent harms rooted in AI business models and corporate power consolidation. These concerning dynamics occur against the backdrop of the growing lobbying power of the tech sector, as well as increased neoliberalization that sees government and independent sources of funding for academic research reduced and supplanted by industry funding. The growing role of such corporate funding with a direct interest in business-friendly results is distinctly visible in academic research on AI ethics. This worrisome dynamic brings up a number of issues about what it means to do research into the ethics of AI technologies. It raises questions about who ‘owns’ AI ethics, and by extension: who is responsible for maintaining ethical standards in academic research? Similarly, the role of private industry in research funding raises questions about the subtle and pernicious ways in which corporations exert pressure over academic work, even when funding is formally described as ‘no strings attached’. Last but not least, the changing landscape of academic funding leads to novel challenges regarding the impact of industry influence on the research agendas, as well as the career trajectories, of the next generation of academics, like the authors of this contribution...\" (Cath & Keyes, 2022) (as well as the developers of this tool)."
  },
  {
    "label": "Critical Discourse Analysis",
    "type": "Class",
    "description": "An interdisciplinary analytical approach that interrogates how texts, symbols, and language construct what's considered right and wrong, or how objects, bodies and relations are made sense of.",
    "provocation": "What social imaginaries are being gathered around an AI system?",
    "references": "Critical Discourse Analysis studies language is association with its socio-political practices. \"...Critical approaches, however, go further and treat social practices, not just in terms of social relationships, but also in terms of their implications for things like status, solidarity, the distribution of social goods, and power (e.g., how language in a job interview functions as a gate-keeping device, allowing some sorts of people access and denying it to others). In fact, critical discourse analysis argues that language-in-use is always part and parcel of, and partially constitutive of, specific social practices, and that social practices always have implications for inherently political things\"(Gee, 2011).  This method can \"provide insight into the social meanings ascribed to AI in the texts...  For example, AI was variously associated with change at speed and scale through terminology such as ‘unprecedented’, ‘radical’, ‘transformation’ and ‘revolution’. Some of these change-associated meanings were dystopian in tone, for example, an ‘unleashed’ phenomenon. Other texts were utopian, constructing AI as ‘generative’ and a ‘solution’. We noticed how this examination of situated meanings intersected with recurrent dualisms, in this instance utopian and dystopian accounts, which persisted across all facets of the analysis...\" (Bearman et al., 2023)."
  },
  {
    "label": "Crowdfunding",
    "type": "Class",
    "description": "A type of funding where an idea is pitched to a larger number of individuals who are asked to contribute small amounts to finance a project.",
    "provocation": "Why did the project choose crowdfunding to fund its AI system for social good?",
    "references": "\"...Crowdfunding can be considered both as an ethical solution to old problems and as a source for new ethical challenges to be addressed. The very concept of crowdfunding, at its core, represents a solution to traditional barriers of access to finance, which resonates well with the utilitarian ethos of reform and social improvement. Similarly, crowdfunding presents an answer to growing scepticism towards, and disillusionment with, traditional financial institutions, which have triggered and overseen cycles of economic booms and busts in recent decades. In this view, anyone with access to internet can potentially raise funds for a project of their choice from anyone else with access to internet. This implies greater democratization in the use and allocation of financial resources, as well as greater say of the public in its choices of future consumption, provisioning of public goods, and the free promotion of ideas....On the other hand, some also view crowdfunding as a source of new ethical problems. Such view challenges the assumption that the ‘wisdom of the crowd’ is coming up with optimal solutions. Here some critics warn about the ‘madness of the crowd’, the ‘tyranny of the majority’, and unintentional legitimization of institutional failures. First, the concerns with the madness of the crowd, involve situations where groups of people can be collectively misguided and even illogical and delusional (Mackay 2006). Such situations are exacerbated by herding behaviours and information cascades, where later decision making is based on inferences from earlier decision making by others ...\" (Shneor et al., 2020)."
  },
  {
    "label": "Customer",
    "type": "Class",
    "description": "An individual or a group whose purchase of goods and services is mediated by an AI system.",
    "provocation": "Are there adequate opt-in opt-out options available to the customer without losing access to the services and products?",
    "references": "\"...Advertisement practices are nothing new; they reach back to the late 1950’s when their primary goal – as it is today –was to learn about customers in order to offer them products and services. However, today’s advertisements pose new challenges. Digital technologies are now devised to peer further into the needs, interests, and motivations of customers. Behavioural advertising, online profiling and ‘behavioural targeting’ have become common tactics for suppliers to more effectively4 offer products5 to customers in the digital environment.... Affinity profiling - grouping people according to their assumed interests rather than solely their personal traits - has become commonplace in the online advertising industry. Online platform providers use behavioural advertisement (OBA) and can infer very sensitive information (e.g. ethnicity, gender, sexual orientation, religious beliefs) about individuals to target or exclude certain groups from products and services,\nor to offer different prices. OBA and affinity profiling raise at least three distinct legal\nchallenges: privacy, non-discrimination, and group level protection...\" (Wachter, 2019)"
  },
  {
    "label": "Data",
    "type": "Class",
    "description": "(To be updated)",
    "provocation": "How was dataset constructed and how does it constitute the reality that it claims to represent?",
    "references": "The entity definition is borrowed from Zins (2007) who collected responses from 57 experts from 16 countires on three concepts: data, information and knowledge. \"...Etymologically, data, as noted, is the plural of datum, a noun formed from the past participle of the Latin verb dare–to give. Originally, data were things that were given (accepted as “true”)... \" (Zins 2007).  Theory-laden approach to data argues that data is constructed, constitutive, subjective, partial, lively and not representative of truth or reality. \"...data assemblages as lively and vital, constantly emerging, recombined and distributed among and between a range of changing actors (Lupton, 2017b, 2017c)...think of these assemblages as more-than-human, possessing lively capacities that encourage us to act and think of ourselves in certain ways. These assemblages also generate capacities that flow beyond us, into the worlds of other humans and nonhumans...\" (Lupton, 2020)"
  },
  {
    "label": "Data As Lively",
    "type": "Class",
    "description": "A type of approach that emphasises the dynamic nature of data",
    "provocation": "What choices do people make around collecting, interpreting, and sharing their data? How do people give meaning to their data, and how are data incorporated into everyday lives, notions of selfhood, and embodiment?",
    "references": "\"Digital data may be characterized as “lively” in a number of ways (Lupton,\n2016a). First, these data are about life itself. Second, they are dynamic, with\ntheir own social lives. They are constantly being configured and reconfigured\nas people interact with online technologies, and are circulated and repurposed\nby a multitude of different actors and agencies. Third, these data are a key part of the global knowledge economy, contributing to commercial, managerial,\ngovernment, and research enterprises (“livelihoods”). And finally, these data\nhave become an influential part of everyday lives, affecting beliefs and behaviors\nand increasingly, people’s life chances via the assumptions and inferences that\nare developed from algorithmic analytics.Indeed, in extending the metaphor\nof lively data, I have drawn on the work of Haraway (2003) to argue that the\ndigital data assemblage may be conceptualized as a companion species to the\nhumans with which it co-evolves (Lupton, 2016b)...\" (Lupton, 2017)\""
  },
  {
    "label": "Data Justice",
    "type": "Class",
    "description": "A design intention with an aim to advance access or use of data to nurture egalitarian relations in the society.",
    "provocation": "How is data being used to gather new forms of relations in the design of an AI system?",
    "references": "\"...That is, data politics is concerned with not only political struggles over data production and its deployments, but how data is generative of new forms of power relations and politics at different and interconnected scales. If indeed data enacts that which it represents, this signifies two things. To collect, store, retrieve, analyse, and present data through various methods means to bring those objects and subjects that data speaks of into being. Data sciences such as statistics, probability, and analytics have emerged not because they have merely quenched our curiosities but because these sciences have been useful for the objects and subjects they have brought into being for the purposes of governing and/or profit. And, to speak constantly about data as though it either\nrepresents or records subjects and objects and their movements, independent from the social and political struggles that govern them, is to mask such struggles...\"(Bigo et al., 2019)"
  },
  {
    "label": "Defamation",
    "type": "Class",
    "description": "A form of text/speech that uses false information to injure a group or an individual's reputation.",
    "provocation": "Who is responsible when a bot commits libel?",
    "references": "\"...In August 2016, Facebook fired the team who had been curating its “Trending Topics” section and replaced them with an algorithm that would automatically recognize and promote popular topics. The move came after months of controversy about Facebook’s handling of Trending Topics, including charges of political bias on the part of the editors managing the feature. About 2 days later, however, “Facebook’s foray into automated news went from messy to disastrous” (Oremus, 2016). For at least 8 hours on August 28, Trending Topics highlighted a popular—but erroneous—article claiming that then-Fox News anchor Megyn Kelly had been fired from the cable TV network because she had endorsed Hillary Clinton for U.S. president. Although Facebook still employed a few human editors who were supposed to watch for algorithmically surfaced hoaxes and fake news, they failed to recognize that the source of this particular article (the website endingthefed.com) was neither a reputable mainstream outlet nor a popular conservative site. Instead, “the Trending review team accepted it thinking it was a real-world topic” (Gunaratna, 2016). In the aftermath, the question of responsibility arose: “Even if algorithms are now running the show, is Facebook legally responsible for what happened . . . ?” (R. Meyer, 2016). In other words, had Facebook’s Trending Topics algorithm defamed Megyn Kelly? Or, more generally, can a bot commit libel?...What happens when automated content libels someone, whether because of erroneous data, poorly programmed algorithms, or some combination that produces not just false information but particularly damaging, reputation-harming material?...\" (Lewis et al., 2019)."
  },
  {
    "label": "Deliberative Forums",
    "type": "Class",
    "description": "A type of research method that facilitates \"extended discussions taking place over two or three days, in which the participants are able to play the leading role in deciding the issues to be discussed and how they are approached\" (Taylor-Gooby et al., 2018).",
    "provocation": "How did the consensus around  'good' choice concerning an AI system emerge and against what alternatives?",
    "references": "AI research at the moment is fairly limited. Qualitative research methods such as deliberative forums are rarely used to map socio-political imaginaries of AI. However, if used creatively, the method can help discuss issues of democracy and political proper surrounding an AI system. \"...Democratic forums come from a tradition that draws on the development of interest in more participative and discursive models of democracy (Mouffe, 2010), and provide five key strengths. Observation of discussion in forums allows us to: (i) explore how people understand issues and link together their ideas about different aspects of the welfare state; this includes: (ii) the identification of particular issues as priorities; and (iii) the justification of those priorities in relation to ideas about how different aspects of the welfare world impact on each other; forums also allow us to: (iv) see how people respond to information from different sources, and what information carries the most weight with different groups; and (v) to explore the way group interaction influences discussion and final conclusions over a more extended period of time than is possible in focus groups (Wakeford, 2007)...\" (Taylor‐Gooby et al., 2018). \"...but what is missing in all of them - as in the deliberative approach - is a proper reflection on the moment of 'decision' which characterizes the field of politics. This has serious consequences, since it is precisely those decisions - which are always taken in an undecidable terrain - which structure hegemonic relations. They entail an element of force and violence that can never be eliminated and cannot be adequately apprehended through the sole language of ethics or morality. We need a reflection of the political proper...\" (Mouffe, 2000)."
  },
  {
    "label": "Deontological Ethic",
    "type": "Class",
    "description": "A rule-based, normative ethical framework that insists upon actions as being morally right or wrong.",
    "provocation": "Can moral rules be truly universalized?",
    "references": "\"...Deontological theories can be depicted as duty-based ethical theories. The word “Deon” originates from the Greek word “Duty”. They focus on the nature of the action itself and also on its motive in order to figure out if it is right or wrong. In contrast to the situation with utilitarianism; consequences do not matter in deciding which act is morally right; it is the rules that determine what motive to act from and what action you should make, i.e. what your ethical duty is.(25) Deontological ethics “Non-consequentialism” suggests that some types of actions such as breaking a promise or killing innocents are wrong in themselves, and not simply wrong because they have bad consequences...\"(Ismail & Benlahcene, 2018)"
  },
  {
    "label": "Design",
    "type": "Class",
    "description": "A deliberate and systematic process of creating, structuring, and planning the system's architecture, functionality, user interfaces, and algorithms to achieve specific goals, optimize performance, enhance user experience, and ensure ethical and responsible behavior in accordance with user needs and intended applications. AI system design encompasses various aspects, including data collection, algorithm development, user interaction, and ethical considerations.",
    "provocation": "How does the design of an AI system interrupt existing relations of inequality or open up space for new egalitarian relations to flourish?",
    "references": "\"...In June of 2015, at the Allied Media Conference in Detroit, a group of 30 designers, artists, technologists, and community organizers took part in the workshop “Generating Shared Principles for Design Justice.” The goal of the workshop was to move beyond the frames of ‘social impact design’ or ‘design for good,’ to challenge designers to think about how good intentions are not necessarily enough to ensure that design processes and practices become tools of liberation, and to develop principles that might help practitioners avoid the (often unwitting) reproduction of existing inequalities...\" (Costanza-Chock, 2018)."
  },
  {
    "label": "Design Justice",
    "type": "Class",
    "description": "A design intention with an aim to advance equitable design\nprocesses and just design outcomes",
    "provocation": "What is the relationship between design and power. How does it contribute to strengthening systemic oppression?",
    "references": "\"... we need\nto better understand how design reproduces the matrix of domination\nthrough varied mechanisms, including the distribution of affordances\nand disaffordances that we encode into technologies (design values);\nwho gets paid to do design work and who controls design processes\n(design practices); the stories that we choose to tell about design (design\nnarratives); the inclusion and exclusion of various kinds of people from\nprivileged design locations (design sites); and the methods we use to\nteach and learn about design (design pedagogies)...\"(Costanza-Chock, 2020)"
  },
  {
    "label": "Design Motive",
    "type": "Class",
    "description": "Design ideas, principles or claims that motivate the design of an AI system.",
    "provocation": "Why is the designer doing what they are doing?",
    "references": "\"...It matters what affects, hope, visions we bring to our desigs for as Haraway has often looped \"It matters what matters we use to think other\nmatters with; it matters what stories we tell to tell other stories with; it matters what knots knot knots, what thoughts think thoughts, what descriptions describe\ndescriptions, what ties tie ties. It matters what worlds make worlds, what worlds make stories...” and what designs design (Haraway, 2016)."
  },
  {
    "label": "Deskilling",
    "type": "Class",
    "description": "One of the harms of AI whereby previous skills of workers are made redundant by introducing machine or technologies into the workplace.",
    "provocation": "How do we grapple with and anticipate the evolving roles of today’s and tomorrow’s workers and citizens and their digitally infused and infected practices?",
    "references": "\"...Here, a third and related confluency is called into play. Researching the digital, researching with and through the digital, and dealing with digitally generated and manipulated data demands new capabilities and knowledges. In the wake of a new technology adoption, the researcher’s or practitioner’s work is potentially both deskilled and upskilled. Deskilling may occur as professional practices are increasingly downloaded to the digital (see also interpassive background relations in Heuristic 5 (Discerning the Spectrum of Human-Technology-World Relations)). But these new arrangements do not evoke only deskilling. Upskilling may also be necessitated, as software and hardware become increasingly sophisticated, demanding fluency with specialized languages, graphical user interfaces (GUIs), and new modalities of interaction (see hermeneutic relations in Heuristic 5 (Discerning the Spectrum of Human-Technology-World Relations)...\" (Adams & Thompson, 2016)."
  },
  {
    "label": "Developer",
    "type": "Class",
    "description": "An individual or a group that programs or codes the AI system.",
    "provocation": "Can the developer bring to the fore the epistemic limits of their technical practices? Under what conditions or cultural environment did they design the AI system?",
    "references": "\"...Another, more subtle reason pertains to AI's ambiguous location between science and engineering. A scientific theory makes truth-claims about the preexisting universe, and so it is generally considered legitimate to criticize someone else's theory on grounds of methodological weakness, fallacious reasoning, lack of fit with the evidence, or compatibility of the evidence with other theories. Engineering design methods, on the other hand, make claims in the context of practical problems, and so the legitimate criticisms relate solely to issues of utility. AI projects are sometimes scientific in intention, sometimes engineering, and sometimes they shift subliminally from one to the other. AI people often make substantive claims about knowledge or learning or language, and yet many of them will respond with indignation to arguments that their projects fundamentally misconstrue the nature of these phenomena; in most cases (the primary exception being Newell and Simon's research group at Carnegie-Mellon University) they will argue not that the claims against their work are empirically false but that they are non sequiturs. Pressed to explain the seeming contradiction, they will generally state that their systems exhibit knowledge-as-such, say, as opposed to human knowledge in particular...The underlying problem is not mendacity but a conflict of languages: norms and discourses of engineering are applied to terms (knowledge, learning, language, and so on) whose meanings are inextricably rooted in the phenomena of human life...A final reason, which I have already discussed above, is that AI discourse makes it exceptionally difficult to conceptualize alternatives to the field's prevailing ideas. Indeed, AI does not have \"ideas\" in any sense that would be familiar from philosophy or literature or social thought; instead it has technical practices, loosely articulated intuitions about those practices, and ways of talking about the resulting artifacts that combine precision and vagueness in specific ways...In these ways, AI's construction of itself as a self-contained technical discipline, though seemingly governed by practical-minded criteria of success and failure, is actually a powerful force for intellectual conservatism. Critics will be asked, \"what's your alternative?\", within a tacit system of discursive rules that virtually rules out alternatives from the start. All the same, I think that the very concept of \"alternatives\" is misleading, and that it is actually impossible to achieve a radical break with the existing methods of the field. This is because AI's existing language and technical practice, like any disciplinary culture, runs deeper than we are aware...\" (Agre, 1997)."
  },
  {
    "label": "Developer As Active Practitioner",
    "type": "Class",
    "description": "An ethical relation that redefines the role of a developer as active practitioner and sense-maker.",
    "provocation": "What's at stake for the developer?",
    "references": "\"...The detached perspective of the moral philosopher and observer is thus replaced by that of the active practitioner and sense-maker: we find ourselves in the lifeworld, understood as a practical and relational space where the question of what to do for and with a plant matters...\" (Coeckelbergh 2018)."
  },
  {
    "label": "Dishonest Anthropomorphism",
    "type": "Class",
    "description": "Anthropomorphism refers to a tendency to think of non-human agents and actors in human likeness, terms and/or forms.",
    "provocation": "How does the design responsd to human sensibilities to anthropomorphize non-human objects?",
    "references": "\"...Unlike simply tricking the user into a misunderstanding, dishonest anthropomorphism leverages people’s intrinsic and deeply ingrained cognitive and perceptual weaknesses against them. Even though people know they’re dealing with a machine, they feel inclined to respond as if they were in the presence of a human being; perhaps they are powerless to behave otherwise. While there are many aspects of artificial intelligence (AI) that deserve the basic cautious approach of any consumer good, the anthropomorphic design aspects of robots and digital entities that we discuss present a challenge to even the canniest among us. Humans are even more prone to anthropomorphizing a robot that walks or talks than a simple appliance that is not designed to look like us, sound like us, act like us, or resemble any being that is alive, like an insect or animal. As more devices and robots are incorporated into our daily lives, dishonest anthropomorphism poses grave threats because bad actors will recognize the value of intentionally exploiting our anthropomorphic tendencies and roboticists who do not understand the power of anthropomorphism will unintentionally create products that are misaligned with consumers’ mental models of what embodied gestures mean...\" (Leong & Selinger, 2019)."
  },
  {
    "label": "Disruptive",
    "type": "Class",
    "description": "A market intervention that disrupts existing business networks or creates a new market niche to generate value.",
    "provocation": "Does the rhetoric of disruption open up new visions or possibilities for the future?",
    "references": "\"...In this paper, I examine the political-philosophical and quasi-religious colourings of contempor-ary high-tech disruption narratives, as circulated and perpetuated by many Silicon Valley-type (bio)-technology firms. Where Hogarth (2017) sees thesefirms suspended in a liminal space between the‘regime of hope’and the‘regime of truth,’I argue that their disruption narratives work as politicaltechnologies, conjuring up a‘theological unconscious’(Muniesa2017), where futures are envisagedas liberatory and essentially faith-based alternatives to the current status quo. Recent works in thesociology of expectations see capitalist futures as multiple and entrepreneurs productively utilizingthis multiplicity (Esposito2013, 2018). In my reading of high-tech disruption narratives, this mul-tiplicity is often paradoxically combined with a narrowing down of all potential futures to one. This political or philosophical techno-vision is elevated to be the only possible alternative to the statusquo; it signals the necessary destruction of the old and the creation of a world that clearly parts with whatever has preceded it. In other words, I propose that through advocating‘the end of uncer-tainty’disruption narratives gain an eschatological character...\" (Geiger, 2020)"
  },
  {
    "label": "Domain",
    "type": "Class",
    "description": "Broader areas such as healthcare, education, finance etc. within which AI systems are being used and deployed. Each domain has unique challenges and use-cases vis-à-vis AI systems.",
    "provocation": "How does AI rework the problems that have been crucial for that domain?",
    "references": "\"...Yet the actual research into AI only took off in the 1950s, when scientists and engineers suggested that formal logic could be applied not just by humans but also by machines – and when machines were powerful enough to undertake these kinds of operations of symbolic reasoning. Much work at the time was driven by the desire to enable machines to think like humans, a criterion that later became known as the Turing Test. However, ‘by the 1980s AI researchers realized that they had neither sufficient hardware nor the knowledge to simulate everything a human can do – and the field fragmented. Instead of working towards one single human-equivalent computer intelligence, research groups splintered off to investigate specific aspects of the larger problem: speech recognition, computer vision and probabilistic inference – even chess’ (New Scientist 2017). Enthusiasm and funding slowly petered out and so by the early 1990s research in the field came to a halt in most places, marred by many disappointments and unrealised promises. Yet over the last decade we have entered what some are calling AI 2.0. The renewed interest in AI research has been accompanied by a change of tack: from what became known as Artificial General Intelligence, whose goal was to replicate the human’s mental functioning as such, to specialised, or ‘narrow’ AI, focused on performing particular tasks and solving singular problems...\" (Zylinska, 2020)."
  },
  {
    "label": "Economic Empowerement",
    "type": "Class",
    "description": "One of the AI4SG domains that aims to use AI to improve access to economic tools for social good.",
    "provocation": "How does a turn to technology reinscribe relations of financial hierarchy while relying on  promises of equal access and empowerment?",
    "references": "\"...Digital financialization; market economy; individual up-with-the-bootstrapslogics, and an ethos of millennial development (that emerged during Wolfensohn's leadership of the World Bank between 1995 and 2005)-these contribute to what I term as the intersection of NGOization and ITization of theglobal.  There are three simple observations ... One is that philanthropy, altruism, and affect form the basis of an increasingly popular mode of marketing globally. The second observation is that the image of the subalternas empowered by connectivity and technology is central to this form of marketing, and the third observation is that the labor needed for the production of this value for the digital subaltern comes both from the technology (IT)sectors and the nonprofit (NPO) and nongovernmental organization (NGO)sectors...\" (Gajjala, 2017)."
  },
  {
    "label": "Economic End User",
    "type": "Class",
    "description": "A type of economic end user who is negatively affected by an AI system",
    "provocation": "(To be updated)",
    "references": "(To be updated)"
  },
  {
    "label": "Economic User",
    "type": "Class",
    "description": "A user of an AI system who is not negatively affected by the use of an AI system.",
    "provocation": "(To be updated)",
    "references": "(To be updated)"
  },
  {
    "label": "Education",
    "type": "Class",
    "description": "One of the AI4SG domains that aims to use AI to improve access to education.",
    "provocation": "How does AI rework the fundamental inequality between the learner and the learned that is at the heart of education discourse? Can human-machine entanglements help interrupt the banking concept of education.?",
    "references": "\"...AI chatbots are the current fascination of EdTech, a discourse Selwyn (2016) found to be full of bullshit. In his reading, the language of transformation and progress pervading EdTech springs from marketing, hype, or simply naive hope rather than 100 years of the research into what has been found to actually transform education—which is in itself very little (Selwyn 2016). There is nothing new here I am pointing to, as we have already been warned about the ‘learnification’ of education (Biesta 2009, 2015a, 2015b; Bayne 2015a), when it is written in languages where teachers are replaced by robots (Selwyn 2019). This is evident in the AI in education research literature where teachers have been found to be conspicuous by their absence (Zawacki-Richter et al. 2019). Although an alternative prediction is that we will have more human teachers in the classroom of the future, not less, and they will be needed to orchestrate sophisticated AI ensembles (Dillenbourg 2016)....So will robots replace or generate teachers? Will we escape the human machine distinction altogether and reinvent ourselves as cyborgs and teacherbots, enacting entangled pedagogies of the postdigital? (Haraway 1985/1991; Bayne 2015b; Fawns 2022)....The conversation will go on and on and in many directions\" (Costello, 2023) . There is also utility in Rancière’s (1991) committed emphasis for the need to start from a premise of equality of intelligence, ...Or, to put it in the words of Brazilian educator Paulo Freire (1970), of the need to avoid a ‘banking concept of education’, whereby ‘knowledge is a gift bestowed by those who consider themselves knowledgeable upon those whom they consider to know nothing’... (p. 58; see also Galloway, 2012)\" (Gerrard, 2021)."
  },
  {
    "label": "Education End User",
    "type": "Class",
    "description": "A type of education end user who is negatively affected by an AI system",
    "provocation": "(To be updated)",
    "references": "(To be updated)"
  },
  {
    "label": "Education User",
    "type": "Class",
    "description": "A type of education user that uses AI system to deliver its services.",
    "provocation": "(To be updated)",
    "references": "(To be updated)"
  },
  {
    "label": "End User",
    "type": "Class",
    "description": "Users who are affected by the system and depend on users and developers.",
    "provocation": "How do the users and developers of a system enact their power over the end users—the ones affected by the system? How do end users navigate this assymetry vis-a-vis users and developers?",
    "references": "\"...Despite this intuition, there remains an inconsistency in the debate between the socio-economic importance of power and the level of conceptual clarity regarding what power is...Domination, as understood by the neo-republican framework, occurs when one is subjected to a superior and unaccountable power (Pettit 1997)...My argument is as follows: first, the moral wrong of domination requires both superior and unaccountable power (Pettit 1997). Second, following the work of Cristiano Castelfranchi (2003), there is a power-dependence relation between those who shape a system (i.e., developers and users) and those affected by a system (i.e., end-users). So how does Castelfranchi’s framework relate to ML systems? Here, I argue that the influence of developers and users on an ML system produces a dependence asymmetry between those who develop and use the system and the end users. Given that (1) the developers and users of systems have an influence on the system’s behaviour, and (2) the system has an effect on the end-users, the end-users depend to some extent on the developers and users to design and deploy the system in such a way that it meets the end-users needs, upholds their rights, and respects democratic values like privacy, freedom, and autonomy. This dependence then, following Castelfranchi, automatically  entails that the developers and users have some ‘power-over’ the system’s end-users...\" (Maas, 2022)."
  },
  {
    "label": "Environmental Impact",
    "type": "Class",
    "description": "A type of risk where the hardware and energy required to build and maintain AI system has negative impacts on the environment.",
    "provocation": "How is 'nature' shaped, reshaped, obfuscated, or erased in the design of the AI system?",
    "references": "\"...Seb Franklin notes how technology users ‘experience their devices as media of frictionless connection’. This is a good description of the denial of materiality in today’s cultures of consuming and thinking about technology. Such a relation of repression or denial ignores the high carbon footprint of networked devices, the waste they create and the hidden labour that goes into making them. Beyond hardware, too, the data that are routinely gathered from Internet-connected devices and used to train AIs can easily seem to belong to an abstract, immaterial sphere quite separate from material bodies and environments\" (Ring, 2023). \"Power is also seen in the way algorithms assess risk (Amoore, 2011, 2018; Liu and Graham, 2021); in the way they make decisions on environmental management with algorithmically underpinned technologies and analytics generating new understandings of nature and new ways of managing conservation (Lockhart and Marvin, 2020; Adams, 2019)...\" (Maalsen, 2023)"
  },
  {
    "label": "Equality and Inclusion",
    "type": "Class",
    "description": "One of the domains of AI4SG that aims to use an AI system to improve social equality and cohesion.",
    "provocation": "Who sets the agenda, who designs, who deploys, who uses?",
    "references": "\"...While the eradication of poverty and inequalities features within many goals, the agenda does not always well acknowledge the relations which structure inequality – concentrations of wealth, decision-making authority, knowledge or social status, which are unevenly experienced across diverse social groups – or their specific manifestations in urban areas (Gupta and Vegelin, 2016; Fukuda-Parr, 2019). For such critics, the potential for the SDGs to legitimate ‘business as usual’ may further entrench, rather than alleviate, the exclusions of urban poor communities, falling short of its ‘transformative’ potential...\"(Butcher, 2020)."
  },
  {
    "label": "Equality End User",
    "type": "Class",
    "description": "A type of equality user who is negatively affected by the use of an AI system.",
    "provocation": "(To be updated)",
    "references": "(To be updated)"
  },
  {
    "label": "Equality User",
    "type": "Class",
    "description": "A type of equality user who is not negatively affected by the use of an AI system.",
    "provocation": "(To be updated)",
    "references": "(To be updated)"
  },
  {
    "label": "Equity",
    "type": "Class",
    "description": "An ethical parameter that pivots upon the values of fairness and equality.",
    "provocation": "What is a just social order?",
    "references": "\"When I teach this material to students, I warn them that the subject does not exist. Among all nonexistent subjects, in fact, equity occupies a distinguished position because it fails to exist in several different ways. The arguments against existence take three different forms. The first is that equity is merely a word that hypocritical people use to cloak self-interest. It has no intrinsic meaning and therefore fails to exist. The second argument is that, even if equity does exist in some notional sense, it is so hopelessly subjective that it cannot be analyzed scientifically. Thus it fails to exist in an objective sense. The third argument is that, even granting that equity might not be entirely subjective, there is no sensible theory about it, and certainly none that is compatible with modern welfare economics. In short, it fails to exist in an academic sense. I hasten to add that equity, or at least a close relative, is very much alive and occupies a prominent place in moral philosophy. For philosophers, however, the central problem is to define what we mean by a just social order. Equity in this sense is concerned with the proper distribution of resources, rights, duties, opportunities, and obligations in society at large.\" (Young, 1995)."
  },
  {
    "label": "Ethic",
    "type": "Class",
    "description": "A set of moral principles that guide human behavior, that help distinguish between right and wrong based on personal values, societal norms, and political necessities.",
    "provocation": "What is ethics?",
    "references": "\"...A connection between critical thinking and ethics is only possible, however, when ethics is defined not as a static list of rules but as a \"mode of questioning,\" As a mode of inquiry, ethics invites [one] to consider: Who is responsible? For what is one responsible and to whom?...\" (Porter, 1992)."
  },
  {
    "label": "Ethic Bashing",
    "type": "Class",
    "description": "Tendency to trivialize ethics as a mode of inquiry",
    "provocation": "Is the social scientists's critique of existing practices merely adopt an instrumental view of ethics or does it expand our horizons and thicken\nour moral commitments?",
    "references": "\"...On the other hand, the technology community’s criticism and scrutiny of instances of ethics washing often borders into the opposite fallacy, which we call “ethics bashing”\". \"In parallel to the growth of ethics washing, its condemnation has led to a tendency to engage in “ethics bashing.” This consists in the trivialization of ethics and moral philosophy now understood as discrete tools or pre-formed social structures such as ethics boards, self-governance schemes or stakeholder groups\".  \"Grappling with the role of philosophy and ethics in tech policy requires moving beyond both ethics washing and ethics bashing and seeing ethics as a mode of inquiry\" that can expand our horizon...\" (Bietti, 2020). \n\"The fast-moving wave of critique that defined the ‘‘tech lash’’ is now being subsumed by an even larger wave of what Elettra Bietti calls ‘‘ethics bashing.’’ Where the tech lash centered on exposing the bad behavior of some of the world’s largest tech corporations, this next wave addresses the rise of ‘ethics’ as a new industrial agenda, focusing on actions such as the establishment of AI ethics boards, hiring AI ethics teams, and funding AI ethics research. Critics have fairly interpreted these actions as efforts to instrumentalize ethics, to reduce it to another form of industrial capital, or to co-opt and capture researchers as part of efforts to control public narratives...\" (Economies of Virtue – The Circulation of ‘Ethics’ in AI, 2022)"
  },
  {
    "label": "Ethic Dumping",
    "type": "Class",
    "description": "A type of unethical risk wherein researchers conduct prohibitive research in low-income countries or settings which have loose regulatory frameworks.",
    "provocation": "How is AI deployment mobilized among low-income or vulnerable groups, through what rhetorics, and when is 'good', good enough?",
    "references": "\"...It is with this historic lens that we examine the practice of beta-testing, which is the testing and fine-tuning of early versions of software systems to help identify issues in their usage in settings with real users and use cases. In the testing of predictive systems, we find several clearly exploitative situations, where organisations use countries outside of their own as testing grounds—specifically because they lack pre-existing safeguards and regulations around data and its use, or because the mode of testing would violate laws in their home countries (UNCTAD 2013). This phenomenon is known as ethics dumping: the export of harms and unethical research practices by companies to marginalised and vulnerable populations or to low- and middle-income countries, and which often aligns “with the old fault lines of colonialism” (Schroeder et al. 2018).\"\" (Mohamed et al., 2020) \"\"In Latin America, IBM, Microsoft, NEC, Cisco, Google are commonly involved in AI projects developed by the public sector from the region. Every project feeds databases and provides intelligence for machine learning systems of these companies, which can use these less regulated environments, where enforcement of privacy rights is weak, as laboratories to test and improve their systems, normally unaccountable to possible harmful consequences...\"(Varon & Peña, 2021)."
  },
  {
    "label": "Ethic Lobbying",
    "type": "Class",
    "description": "A type of unethical risk wherein private actors (are at least suspected to) try to use self-regulation about the ethics of AI in order to lobby against the introduction of legal norms, or in favour of their watering down or weakening their enforcement, or in order to provide an excuse for limited compliance (Floridi 2019).",
    "provocation": "What do big actors hope to achieve when they endorse AI ethics?",
    "references": "\"At the Media Lab, I learned that the discourse of ‘ethical AI,’ championed substantially by Ito, was aligned strategically with a Silicon Valley effort seeking to avoid legally enforceable restrictions of controversial technologies. A key group behind this effort, with the lab as a member, made policy recommendations in California that contradicted the conclusions of research I conducted with several lab colleagues, research that led us to oppose the use of computer algorithms in deciding whether to jail people pending trial\". \"Regardless of individual actors’ intentions, the corporate lobby’s effort to shape academic research was extremely successful. There is now an enormous amount of work under the rubric of ‘AI ethics.’ To be fair, some of the research is useful and nuanced, especially in the humanities and social sciences. But the majority of well-funded work on ‘ethical AI’ is aligned with the tech lobby’s agenda: to voluntarily or moderately adjust, rather than legally restrict, the deployment of controversial technologies. How did five corporations, using only a small fraction of their budgets, manage to influence and frame so much academic activity, in so many disciplines, so quickly?\" (Ochigame, 2022)"
  },
  {
    "label": "Ethic Shirking",
    "type": "Class",
    "description": "An ethical malpractice of applying double standards in moral evaluations.",
    "provocation": "Whose ethics? Whose social good?",
    "references": "\"...The counterpoint to ethics dumping is ethics shirking: what is not done to protect people when harms emerge beyond what is demanded from legal or regulatory frameworks (Floridi 2019). As an example, Cambridge Analytica (CA) elected to beta-test and develop algorithmic tools for the 2017 Kenyan and 2015 Nigerian elections, with the intention to later deploy these tools in US and UK elections. Kenya and Nigeria were chosen in part due to the weaker data protection laws compared to CA’s base of operations in the United Kingdom—a clear example of ethics dumping. These systems were later found to have actively interfered in electoral processes and worked against social cohesion (Nyabola 2018). A critical decolonial approach would, for example, lead us to ask early on why the transgression of democratic processes by companies such as CA only gained international attention and mobilisation after beginning to affect Western democratic nations... To do so, we can draw from existing analysis of ICT for Development, which are often based on historical analysis and decolonial critique (Irani et al. 2010; Toyama 2015). These critiques highlight concerns of dependency, dispossession or ethics dumping and shirking, as discussed earlier (Schroeder et al. 2018). Such critiques take renewed form as AI is put forward as a needed tool for social development. Where a root cause of failure of developmental projects lies in default attitudes of paternalism, technological solutionism and predatory inclusion...\" (Mohamed et al., 2020)"
  },
  {
    "label": "Ethic Shopping",
    "type": "Class",
    "description": "The malpractice of choosing, adapting, or revising (“mixing and matching”) ethical principles, guidelines, codes, frameworks, or other similar standards (especially but not only in the ethics of AI), from a variety of available offers, in order to retrofit some pre-existing behaviours (choices, processes, strategies, etc.), and hence justify them a posteriori, instead of implementing or improving new behaviours by benchmarking them against public, ethical standards (Floridi 2019).",
    "provocation": "Is the language of ethics being used to advocate against regulation?",
    "references": "\"...Yet the possibility to implement these solutions in technical design does not answer a more difficult question: how then to differentiate the many ethical frameworks out there and decide which are more likely to deliver appropriate ethics? How to ensure that ethics shopping or ethics washing does not become the default engagement with ethical frameworks or rights-based design? Thus, is a world in which ethics-washing and ethics-shopping are becoming increasingly common, it is important to have common criteria based on which the quality of ethical and human rights commitments made can be evaluated. If not, there is a considerable danger such frameworks become arbitrary, optional or meaningless rather than substantive, effective and rigorous ways to design technologies. When ethics are seen as an alternative to regulation or as a substitute for fundamental rights, both ethics, rights and technology suffer...\" (Wagner, 2018)"
  },
  {
    "label": "Ethic Washing",
    "type": "Class",
    "description": "The malpractice of making unsubstantiated or misleading claims about, or implementing superficial measures in favour of, the ethical values and benefits of digital processes, products, services, or other solutions in order to appear more digitally ethical than one is (Floridi 2019).",
    "provocation": "Why is the team invested in appearing ethical in its design of the AI system?",
    "references": "\"...On the one hand, the term has been used by companies as an acceptable façade that justifies deregulation, self-regulation or market driven governance, and is increasingly identified with technology companies’ self-interested adoption of appearances of ethical behavior. We call such growing instrumentalization of\nethical language by tech companies “ethics washing.” Beyond AI ethics councils, ethics washing includes other attempts at simplifying the value of ethical work, which often form part of a corporate communications strategy: the hiring of in-house moral philosophers who have little power to shape internal company policies; the focus on humane design – e.g. nudging users to reduce time spent on apps – instead of tackling the risks inherent in the existence of the products themselves; the funding of work on “fair” machine learning systems which positively obscures deeper questioning around the broader impacts of those systems on society...\"(Bietti, 2020)"
  },
  {
    "label": "Ethical Parameter",
    "type": "Class",
    "description": "A single characteristic of a larger framework.",
    "provocation": "What do ethical parameters look like in a real-life decision-making context? How are organisations and those within them reckon with the complex ethical tug-of-war between ‘the bottom-line’ and upholding ethical principles?",
    "references": "\"Meta-analyses of AI ethics proposals have thus far focused mainly on classifying and comparing the ethical principles suggested, where some convergence can be identified for principles like transparency, fairness, privacy and responsibility. What is less clear and needs investigation are other variables for these proposals like scope, applicable context, ownership of or responsibility for the process, method of implementation and representation of stakeholders\" (Ayling & Chapman, 2022)."
  },
  {
    "label": "Ethical Theories",
    "type": "Class",
    "description": "A framework that helps decide the most just and ethical course of action.",
    "provocation": "How should artificial moral agents make decisions? Is one moral theory better suited than others for machine ethics?",
    "references": "(To be updated)"
  },
  {
    "label": "Ethico Political Care",
    "type": "Class",
    "description": "A redefinition of care ethics that asks how ethical aspirations to ‘do good’ are entangled in politically charged care practices that are ‘ambivalent, contextual, and relational’ (Martin et al. 2015: 631) and can be fraught with histories of sexism, racism, capitalism and colonialism (Murphy 2015).",
    "provocation": "(To be updated)",
    "references": "\"...We take as a point of departure Puig de la Bellacasa’s ‘speculative ethics’ (2011, 2017), which puts constructivist accounts of science, technology and society (STS) into play with Joan Tronto’s political theory on the ethics of care (Tronto 1993)...Among other things, Bellacasa’s work offers a “commitment to generating a ‘speculative’ critique which offers possible alternatives for living a ‘good’ life. Rather than a moral stance or invocation for motherly love, ‘care’ is thus deployed as ‘an analytic or provocation’ (Puig de la Bellacasa 2017: 7)”...Contrary to those who have interpreted Tronto’s care ethics as normative (e.g. Pols 2015), Puig de la Bellacasa asserts that Tronto’s work offers ‘a vision of caring [that] presupposes heterogeneity as the ontological ground on which everything humans relate with exists … Its ontological import gives to care the peculiar significance of being a nonnormative necessity’ (Puig de la Bellacasa 2017: 70). Weaving Tronto’s care ethics together with constructivist accounts of technoscience, Puig de la Bellacasa’s approach has led to a lineage of feminist scholarship in science and technology studies (STS) which foregrounds the ‘ethico-political’ practices of care in technoscience in a wide range of settings (Lindén and Lydahl 2021). These ‘Critical Care’ studies of technology design and use illustrate how ethics often operate in tension with justice — how ethical aspirations to ‘do good’ are entangled in politically charged care practices that are ‘ambivalent, contextual, and relational’ (Martin et al. 2015: 631) and can be fraught with histories of sexism, racism, capitalism and colonialism ...\"(Henry & Oliver, 2022)"
  },
  {
    "label": "Ethics As Political",
    "type": "Class",
    "description": "\"To rethink ethics in a broader manner via engaged epistemology in a way that puts the needs and welfare of the most impacted and marginalized at the center.” (Birhane 2021).",
    "provocation": "What/who is the excluded other of the system that makes them system possible in the first place?",
    "references": "\"...This eccentric form of moral thinking recognizes that the real challenge for ethics is not figuring out a way to include others, but to identify and confront the systemic exclusions of any and all efforts at inclusion as a significant and fundamental aspect of moral thinking itself. What we need to do in the face of the machine, therefore, is not to try to formulate more inclusive forms of moral theory that can account for and incorporate these others, but to recognize the symptom as such and allow it to question the entire history of ethics and its necessary and unavoidable exclusions. This is precisely that kind of thinking that Friedrich Nietzsche (1966) had called “the philosophy of the future,” not only because the symptom of ethics, like the machine, appears to threaten us from the future but because it points in the direction of a kind of thinking that is situated beyond (the very system of) good and evil. This means that the challenge presented to us by the machine is not just a matter of applied ethics; it invites and entrains us to rethink the entire modus operandi of moral philosophy all the way down. This is the task for thinking that is seen in the face or the faceplate of the machine...\" (Gunkel, 2022)."
  },
  {
    "label": "Ethics Manipulation",
    "type": "Class",
    "description": "A type of malpractice that uses the vocabulary of ethics to achieve unfair, inequitable, unjust goals.",
    "provocation": "How is the language of ethics deployed? By whom? To what purpose? What does it do?",
    "references": "\"...The issue is not that ethics is worthless (or toothless) in the face of current AI deployment; it is rather that ethics is used (or manipulated) in such a way that it is rendered ineffective for AI ethics...\" (Rességuier & Rodrigues, 2020)."
  },
  {
    "label": "Ethnographic Research",
    "type": "Class",
    "description": "A type of qualitative method that uses fieldwork to undertake an indepth study of a particular phenomenon, group or society.",
    "provocation": "How to account for nonrational, irrational, or anti-irrational behavior in society?",
    "references": "\"...Since its inception, anthropology has been a restless discipline, dwelling in a constant unsettlement, provoked both by internal and external movements of disciplinary revision. This disquiet is deeply engrained since its founding moments: from the hesitation between positivist and more subjectivist configurations to its persistent fixation with the marginal and the exotic as preferential objects, its recurring reflexivity and self-referentiality, its disciplinary flirtation with philosophy, history, psychology, and other subjects, and the constant threat of disappearance that hovers over it. This unsettlement has often undermined anthropology’s own capacity to become assertive, public, and relevant in several academic and political contexts; but it has also been in many ways its driving force, one that constitutes its\noriginality within the social sciences and humanities. ...anthropology, and ethnography in particular, have also revealed the counterhegemonic stances of antiutilitarianism and audit cultures, arguing for the relevance of long-term, intersubjective research in the production of knowledge (our third moment). From this point of view, ethnography, as practice and heuristic, has become a form of resistance to particular modes of science-making and knowledge production, struggling to sustain its particular temporalities, routines, and generative research against typified, increasingly fast-paced production processes... configurations of social interactions have placed anthropologists in an uncomfortable yet potentially productive position: how to account for nonrational, irrational, or anti-irrational behavior in society? If our task as ethnographic writers is to strive for coherent registers of our observations, detecting logics and continuities, repetitions, similarities, and differences, to what extent are we unconsciously reproducing predetermined ideas of social order and behavior? After all, what is the anthropological interest in involuntary behavior—or voluntarily nonintentional behavior? How do we make sense of nonsense (Rada 2010)? Can we afford to ignore the nonsensical, Pythonesque, or even “bullshit” (Frankfurt 2005) dimensions of social discourse and activity?...\" (Maskens & Blanes, 2013)."
  },
  {
    "label": "Exclusionary Norm",
    "type": "Class",
    "description": "A type of risk wherein the use of AI disproportionately excludes or discriminates against certain individuals or groups,",
    "provocation": "How does the AI system reproduce or reshape existing social hierarchies?",
    "references": "\"...When algorithmic systems fail — and they often do — such failures result in concrete negative outcomes such as job loss or exclusion from opportunities. Landmark work surrounding algorithmic decision-making in recent years has brought to light issues of discrimination, bias, and harm, demonstrating harms and injustices in a manner that is grounded in concrete practices, specific individuals, and groups. Computer Vision systems deployed in the social world suffer from disproportionate inaccuracies when it comes to recognizing faces of Black women compared to that of white men; when social welfare decision-making processes are automated, the most vulnerable in society pay the heaviest price; and search engines continually perpetuate negative stereotypes about women of colour; to mention but a few examples. In short, when problems that arise from algorithmic decision-making are brought forth, we find that those disproportionately harmed or discriminated against are individuals and communities already at the margins of society...\" (Birhane et al., 2022)."
  },
  {
    "label": "Explainability",
    "type": "Class",
    "description": "One of the ethical parameters that insist on the need to make the decision making of AI systems human-understandable.",
    "provocation": "What question the explanation is really answering and what does it not explain?",
    "references": "\"...Despite the recent resurgence of explanation and interpretability in AI, most of the research and practice in this area seems to use the researchers' intuitions of what constitutes a ‘good’ explanation. Miller et al. [132] shows in a small sample that research in explainable AI typically does not cite or build on frameworks of explanation from social science. They argue that this could lead to failure. The very experts who understand decision-making models the best are not in the right position to judge the usefulness of explanations to lay users — a phenomenon that Miller et al. refer to (paraphrasing Cooper [132], [31]) as “the inmates running the asylum”. Therefore, a strong understanding of how people define, generate, select, evaluate, and present explanations seems almost essential...\" (Miller, 2019). \n\"The detective, questioning a suspect about a murder, asks the suspect, Why did he die? The suspect tentatively suggests, Well, everyone has to go sometime, sir. Here, the suspect is dodging the detective's \"real\" question. The effect of such differing spaces of alternatives is not always a joke; what aspect of a given state of affairs we take to be problematic radically\naffects the success or failure of potential explanations. For an explanation to be successful, it must speak to the question at hand, whether explicit or implicit, or else we will have failures of fit...What we need, therefore, is some way of representing what is really getting explained in a given explanation, and what is not\". Explanataroy frames are shifting. \"Perhaps the most interesting cases of changes in explanatory frames are ones in which there is a shift in the nature of the question being asked. Explanations are sometimes answers to explicit questions. Why is the sky blue? Why do metals expand when heated?4 But often there is no explicit question at hand, and in those cases it can be very instructive to perform a kind of diagnostic inference and ask what question the explanation is really answering...\" (Garfinkel, 1981). \n\nThis is more so the case with emerging socio-technical objects such as AI...\"."
  },
  {
    "label": "Fairness",
    "type": "Class",
    "description": "An ethical parameter that aims to remedy or prevent wrongful harms resulting from biased algorithmic outputs.",
    "provocation": "Would a fair distribution of an algorithm’s predictions or decisions mitigate injustices raised by the algorithmic systems",
    "references": "“...seeking one-off static solutions in terms of fairness metrics is inadequate, because narrow scope is susceptible to ‘ethics washing’ [4, 32, 48], insofar as making minor mathematical changes to algorithmic outcomes is supposed to be a putatively valuable ethical or legal solution to certain algorithmic decision-making problems...However, across the board, whether they are explicitly defended as such or not, most mathematical criteria for algorithmic fairness can be understood as mathematical translations of some ideals or principles for a local distribution of computational or material benefits or burdens among people....But would a fair distribution of an algorithm’s predictions or decisions mitigate injustices raised by the algorithmic systems? Not always, if we truly pay attention to the sociotechnical nature of algorithms. In the next section, I defend this contention by arguing that structural injustices are relevant to our conceptions of algorithmic fairness. The importance of the distributive fairness metrics (locally understood) depends on the power structures and social dynamics in and through which the algorithm operates....” (Kasirzadeh, 2022)"
  },
  {
    "label": "Farmer",
    "type": "Class",
    "description": "A person or a collective engaged in agriculture activities.",
    "provocation": "Does the design of the AI system help reimagine the relationship between food, life, and the larger ecosystem? Does it involve the most marginalized actors within the food ecosystem in its reimagination?",
    "references": "\"...If information is to be the new substrate of farming, then it seems we are faced with a choice. On one hand, to use algorithmic control to preserve an imperious, masculine order of factory farming with a new intensity of control ... where behemoth corporations fight over growing shares in worldwide control of land, labor, and food and governments exert digitally facilitated social control in the name of sustainability and ecosystemic sovereignty. On the other, to take the fineness, the kind of granularity of control and adaptability precision algorithm technologies might offer as a chance to do something genuinely revolutionary: to try and build new relationships to food, land, other species, and one another...within the more limited scope of agriculture, I see promise for rethinking the use of PA technology along the lines of what Kate Crawford has called a design ideal of “agonistic pluralism” (2016). Unlike the functionalist rationality of algorithmic systems which enact universalist, black-boxed logics of productivity towards control over the production of surplus value, agonistic perspectives are premised upon an “ongoing struggle between different groups and structures—recognizing that complex, shifting negotiations are occurring between people, algorithms, and institutions, always acting in relation to each other” (2016: 82–83). PA shifts the scale of attention and intervention from field-level to sub-field control, but it does not question the monocrop, factory-field itself, the literal and figurative ground it is built upon. Yet there is no inherent reason that sensor and processing technologies, which permit more finely grained interventions in food production, could not be designed to facilitate greater ecological complexity without compromising productivity. If, at present, machine learning is designed around a commodity logic towards more efficient maintenance of the conditions of production, i.e. through neural networks designed to automatically recognize and eliminate “weeds” and other pests, agonism in this context could mean finding ways to allow for greater floral and faunal complexity around fields, using robotics, automation, and algorithmic machine learning to negotiate the conflicts in a multi-species ecological milieu (cf. Tsing, 2015)...\"(Miles, 2019)"
  },
  {
    "label": "Feminist Ethic",
    "type": "Class",
    "description": "An ethical framework that seeks to address and rectify traditional ethical theories' historical androcentrism (male-centered focus) by promoting values such as equity, justice, and empathy, with a particular emphasis on the experiences and concerns of women and marginalized gender groups.",
    "provocation": "How does the sociotechnical system configure gender and sex assemblages? How is gender and/or sex mobilised as analytical categories by the AI system?",
    "references": "\"...Our version of feminist ethical theory thus has several distinguishing features. First, it utilizes the categories of gender and other inseparable categories of social difference and hierarchy on the levels of theoretical as well as practical ethics. Second, it enlarges the domain of ethics to include ethics itself: we undertake the ethical analysis of ethical analysis, the ethical theory of ethical theory. We see con- temporary ethical theory as a discourse situated in a larger society and we ask who defines it and how their - and its authority is maintained; we also see ethical theory as a professional practice and so we are led to examine such aspects of that practice as canon formation, prizes, prestigious offices, and lectureships. Finally, our work is - or aspires to be - distinguished by its self-reflectiveness: we try to be con- scious of the assumptions and implications of our own ethical theorizing, including their practical consequences; we seek to produce ethical theory that we acknowl- edge to be partial and provisional from our own explicitly situated perspectives...\"(Jaggar, 2013)"
  },
  {
    "label": "Financial Institutions",
    "type": "Class",
    "description": "Financial institutions are organizations that provide a wide range of financial services to individuals, businesses, and governments. These services typically include banking, lending, investment, and insurance activities.",
    "provocation": "(To be updated)",
    "references": "(To be updated)"
  },
  {
    "label": "Focus Group",
    "type": "Class",
    "description": "A type of research method that brings together a small group of people to answer questions in a moderated setting.",
    "provocation": "What was the purpose of using FGDs as a method? How was it conducted? How was the data analyzed?",
    "references": "\"...While focus groups, in some form at least, are now becoming an established part of the methodological tool kit, how they are adopted and adapted remains of crucial concern. It is important to understand \"whether focus groups are simply added to a shopping list of potential methods or whether they are employed in a more challenging way...Finally, we would note that in order to explore the full potential of focus groups it is necessary to ask questions about the research enterprise itself. Such enquiry should include questions about the relationship between research participants and group facilitators and between funding bodies and research teams, but it should also include questions about relationships within research teams themselves...\" (Barbour & Kitzinger, 1998)."
  },
  {
    "label": "For Profit",
    "type": "Class",
    "description": "A type of organization that operates on for-profit basis.",
    "provocation": "\"Is the wealth-creation imperative inherent in for-profit organizations really compatible with optimal social impact?\"",
    "references": "\"\"\"...It may be feasible to marry a social purpose to a for-profit structure, but it is\nnot easy. Even ventures such as Shorebank Corporation and Grameen Bank,\nwhich have withstood the test of time and received much acclaim, have\nencountered major challenges.. While the nonprofit structure\ndoes impose some constraints on raising capital and distributing profits, many\nfor-profit social ventures are also limited in their ability to take full advantage\nof the capital markets and produce significant profits and returns...\"\" (Dees & Anderson, n.d.)\""
  },
  {
    "label": "For Whom",
    "type": "Class",
    "description": "A question situated in the ethical-political practice of care that critically evaluates what it means to care and how the object that is to be taken care of is constructed, presented, and studied.",
    "provocation": "How does distribution of power, privilege and resources lead to inadequate care in society?",
    "references": "\"...Care sounds charged to the feminist-attuned not only because of the material practices it signifies but also because they tend to ask critical questions\nsuch as who will do something, how and for whom? as well as if, why\nand how something has come to be devalued. Care convokes trouble and\nworry for those who can be harmed by an assemblage but might be unable\nto voice their concern and need for care...\" (Bellacasa, 2017)"
  },
  {
    "label": "Funder",
    "type": "Class",
    "description": "A type of actor that provides financial support to the team developing the AI system.",
    "provocation": "What reasonable critique is allowed within funded research and what is foreclosed?",
    "references": "\"...On multiple occasions, I inquired whether there was something in the terms of reference of our research grants with the companies that prevented us from highlighting these structural concerns. I would receive many answers that eventually were a version of the following: ‘No, we can say what we want. There are no strings attached to this funding. But we will not tell them to change the business model.’ The idiom ‘no strings attached’ meant that the funding presumably came without any requirements for the content of the research. This statement was true in only the narrowest reading of the sentence. The signed agreements between academics and industry funders might not have spelled out any limitations on the nature of the critique, or its direction towards the structural forces underpinning industry success. Yet, the unspoken agreements around scope, including the practice of doing the research without veering into immanent critique, did pose real limits. In many of the steps preceding the start of the research, industry funders took decisions that meant that they were likely to invite academics that were willing to improve industry status quo, rather than ‘disrupt’ it.... Industry funding shapes research; not by directly commanding certain outcomes but by amplifying questions that industry is comfortable answering. It thereby shapes the contours of reasonable critique and which harms industry should answer to or not...\" (Cath & Keyes, 2022).\""
  },
  {
    "label": "Government Agency",
    "type": "Class",
    "description": "A government agency is a specialized organization established and funded by a government to perform specific functions, tasks, or services, often related to regulation, administration, or public service delivery.",
    "provocation": "How the use of AI in the public sector can be intensifying existing power asymmetries and governance practices?",
    "references": "\"...The public sector's predicament [concerning the widespread adoption of AI] is a tragic double bind: its obligations to protect citizens from potential algorithmic harms are at odds with the temptation to increase own efficiency - or in other words - to govern algorithms, while governing by algorithms. Whether such dual role is even possible, has been a matter of debate (Lodge & Mennicken, 2017). The challenge stems from algorithms' intrinsic properties, that make them distinct from other digital solutions, long embraced by the governments: vast computing power - exceeding human cognitive capabilities; ‘learning’ - autonomous knowledge creation happening without proper supervision; profiling - categorizing traits and behaviours; and nudging - incentivizing compliance - these all create externalities that rule-based programming lacks. As the pressures to deploy automated decision making systems in the public sector intensify, it is important to examine how machine learning and bureaucracy have both “become generalisable modes of rational ordering based on abstraction and deriving authority from claims to neutrality and objectivity” (McQuillan, 2019). It is with that in mind, that we shall consider our research question: how the use of AI in the public sector can be intensifying existing power asymmetries and governance practices?...\" (Kuziemski & Misuraca, 2020)"
  },
  {
    "label": "Government Funding",
    "type": "Class",
    "description": "A type of funding offered by state or national agency, ministry from the public funds.",
    "provocation": "How does the government's interest in AI reshape the relationship between the state and citizens?",
    "references": "\"...The recent interest in the university–industry interface reflects a proliferation of industry funding of academic research activity. By its very nature, private industry has an incentive, at times, to privatize the intellectual commons and look for short-term, highly applicable results... To some extent, this concern is not new. In the US, government research grants have often come from progammatic, mission-oriented agencies charged with achieving very practical goals. These pragmatic considerations may lead agencies to insist on the production\nof immediately useful knowledge at the expense of traditional academic scholarship... The independence of funding decisions from academic output highlights the fact that much university research funding goes to researchers who produce results of moderate academic value but of perhaps high value to sponsors. These researchers occupy a middle ground between corporate researchers and the traditional view of the Ivory Tower...\" (Goldfarb, 2008).\""
  },
  {
    "label": "Group",
    "type": "Class",
    "description": "A collection of individuals who are members of a group based on their identity, ideas, beliefs or practices.",
    "provocation": "How is marginality understood in the design of an AI system?",
    "references": "\"...However, much remains unknown about emerging technologies and social innovation in the context of marginalized communities. For example, how do we define or conceptualize marginalization? What are the main digital disadvantages for marginalized communities? What are the unique needs and information behaviors of these communities? To what extent do technologies empower marginalized communities and what are the associated challenges? What applied methodologies should researchers adopt and adapt in order to have an impact in the area of racial and social justice? How should we evaluate the role of emerging technologies such as virtual reality, social robots, artificial intelligence, digital library interface design, and big data analytics in promoting social and emotional wellbeing and are their uses culturally appropriate? These are just a few of the many questions that need to be investigated as digital innovation rapidly advances and threatens to further disadvantage marginalized groups...\" (Du et al., 2020)"
  },
  {
    "label": "Hate Speech",
    "type": "Class",
    "description": "A type of speech that aims to exacerbate polarization in the society.",
    "provocation": "How is the social and the technical entangled in the practices of hatespeech and polarization?",
    "references": "\"...These scholars, and many others, argue that the causes of this sectarian polarization are both political—such as the sorting of racial and other identities into distinct parties and the embrace of sectarianism by elites—and tied to broader shifts in media, including the rise of social media and platforms (e.g. Törnberg, 2022). Fittingly, these scholars spend considerable time thinking through what is to be done to mitigate this sectarianism, including platform interventions to encourage more thoughtful deliberation, crowdsourcing false and hyperpartisan content, and algorithmic interventions to deemphasize supposedly harmful content in people’s feeds. This article—and many more—reveals how polarization and platforms consume the field’s imaginary when diagnosing our contemporary democratic ills and provides a reliable go-to for both blame and intervention...\" (Kreiss & McGregor, 2023)."
  },
  {
    "label": "How to Care",
    "type": "Class",
    "description": "\"A question situated in the ethical-political practice of care that critically evaluates the practice of caring and start from an understanding that \"what care can mean in each situation cannot be resolved by ready-made formulas\".\"",
    "provocation": "\"...First, because it exposes the existential domains of care as something open-ended—everything we do. Second, because it points to how the “ethics” in an ethics of care cannot be about a realm of normative moral obligations but rather about thick, impure, involvement in a world where the question of how to care needs to be posed. That is, it makes of ethics a hands-on, ongoing process of recreation of “as well as possible” relations and therefore one that requires a\nspeculative opening about what a possible involves...\" (Bellacasa, 2017).\"",
    "references": "(To be updated)"
  },
  {
    "label": "Human",
    "type": "Class",
    "description": "Type of actor identified as human",
    "provocation": "What kind of a subject gets created in the mangle of technoscience?",
    "references": "\"...production not only creates an object for the subject but also a\nsubject for the object...\" (Marx, 1993)"
  },
  {
    "label": "Human Machine Relation",
    "type": "Class",
    "description": "Refers to the ways in which humans and machines interrogate and coproduce each other.",
    "provocation": "How does the design of an AI system generate algorithmic potentials, practices and epistemes?",
    "references": "\"...Algorithms oppress (Noble, 2018); algorithms are violent (Safransky, 2020); algorithms can be ‘mad’, ‘aberrant’ and ‘unreasonable’ (Amoore, 2020); algorithms work, algorithms anticipate, assess risk, algorithms have social power (Beer, 2017); algorithms match us – to partners, services, properties – algorithms do many things. These busy algorithms have not escaped the attention of geographers who have looked at both the pernicious effects of algorithmic acts and to some extent the potential benefits they may also bring. Much of this work on algorithms has emerged as part of a critical ‘digital turn’ in geography (Ash et al., 2018). The recognition that technologies, software and algorithms do ‘work’ in the world is evident across the discipline – from mediating and governing cities to producing space (Kitchin and Dodge, 2011) to influencing markets (Fourcade and Healy, 2017), nature (McLean, 2020; Adams, 2019), housing (Fields, 2019) and the everyday, algorithms are working for, with and against us. Despite this work, Del Casino et al. (2020: 606) argue that less attention has been paid to thinking through ‘the reimagination of human-nonhuman relations, subjectivities, and potentialities that come to be possible’ in algorithmic life (Del Casino et al., 2020: 606). Indeed, it is undeniable that geographers have predominantly paid attention to the more harmful effects of algorithms, producing necessary and important critiques, yet in doing so overlooking the many generative and exciting possibilities of algorithms, such as their potential for care, or alternative ways of seeing...\" (Maalsen, 2023)."
  },
  {
    "label": "Identified Harm Risk",
    "type": "Class",
    "description": "Negative impacts of AI systems that have been recognized so far.",
    "provocation": "Is the conversation around harms and risks a matter of fixing the existing system fixture?",
    "references": "\"...Most of the existing work on the power or effect of algorithms is broadly considered with their harmful implications. Onuoha (2018) posits ‘algorithmic violence’ as term that reflects digital and data-driven inequity. It is ‘the violence that an algorithm or automated decision-making system inflicts by preventing people from meeting their basic needs. It results from and is amplified by exploitative social, political, and economic systems, but can also be intimately connected to spatially and physically borne effects’ (Onuoha, 2018). This follows a line of thought put forward by feminist scholars on the discriminating nature of algorithms, which code in the existing prejudices of the social, economic, racial and political structures within which they are produced (Noble, 2018; Eubanks, 2017)....The underlying basis of these arguments is that algorithms treat people unequally because of the bias that is coded into them via the individual and institutional ideologies behind them. Because computer programming and technology is a middle-class male dominated profession, then the algorithms they produce ‘see’ the world in similar ways and thus perpetuate the same discriminatory practices, further amplified by the entanglement of technology with economies and governance. Understanding algorithmic power and harm therefore requires acknowledging the uneven power relations in which they are produced and which they in turn perpetuate\" (Maalsen, 2023). One could \"distinguish between two broad varieties of responses to algorithmic harms: how Big Tech-the chief actor of algorithmic harms-has quickly adopted a stance of solidarity to resist them; and refusals that emerge from beyond Big Tech and raise philosophical provocations about what it means to construct life outside the ambit of Big Tech-architected harms and mitigations...\"(Ganesh & Moss, 2022). \n\nA general purpose, open taxonomy of AI, algorithmic, and automation risks and harms: https://www.aiaaic.org/projects/ai-algorithmic-risks-harms-taxonomy"
  },
  {
    "label": "Immigrant",
    "type": "Class",
    "description": "A type of user who lives in a foreign country to settle as permanent residents.",
    "provocation": "How does the discourse of efficiency rework who is percieved as desirable and undesirable immigrant?",
    "references": "\"...states and international organizations are increasingly turning to artificial intelligence as a tool to support the implementation of their migration or asylum management policies and programs. Such policies and programs may have very different goals; they may aim to restrict movement and control migration or access to asylum; they may seek to speed up the processing of economic migration or to support enforcement inland, but they may also aim to provide more efficient assistance to asylum seekers. The common element in these very different goals is the search for efficiency...\"(Nalbandian, 2022)"
  },
  {
    "label": "Inaccuracy",
    "type": "Class",
    "description": "A type of harm ensuing from  incorrect or misleading results, predictions, or information, potentially causing harm by leading to erroneous decisions, misinformation, or mistrust in the technology's reliability.",
    "provocation": "What does an accurate or inaccurate system do?",
    "references": "\"...Much research on the law and policy concerns related to increasing use of algorithms has focused on ways to detect or prevent algorithmic misbehavior or mistakes. However, some problems result when algorithms perform too well rather than too poorly. This Article makes the case that significant individual harms and social welfare losses alike can and already have occurred when algorithms are too performant...\" (Nielsen, 2022)."
  },
  {
    "label": "Inequality",
    "type": "Class",
    "description": "Exacerbation or perpetuation of existing social, economic, or opportunity disparities by artificial intelligence systems.",
    "provocation": "Where does one even begin?",
    "references": "\"To some extent, the idea of centering the disproportionally impacted shares some commonalities with aspects of participatory design, where design is treated as a fundamentally participatory act, and even aspects of human-centered design, where individuals or groups within a society are placed at the center. However, the idea of centering the disproportionally impacted goes further than human-centered or participatory design as broadly construed. While the latter approaches often neglect those at the margins and shy away from power asymmetries and structural inequalities that permeate the social world, and “mirror individualism and capitalism by catering to consumer's purchasing power at the expense of obscuring the hidden labor that is necessary for creating such system” for the former, acknowledging these deeply ingrained structural hierarchies and hidden labor is a central starting point\"(Birhane, 2021)."
  },
  {
    "label": "Information Disorder",
    "type": "Class",
    "description": "Dissemination of false, misleading, or harmful information facilitated by artificial intelligence systems. It includes the generation, amplification, or manipulation of misleading content, leading to confusion, misinformation, and potentially harming individuals, society, or democratic processes.",
    "provocation": "What's more relevant that the information is false or is it harmful?",
    "references": "\"...What should be of paramount importance, in the fight against information disorders, is the potential of false information to cause harm. Disinformation and malinformation are propagated with intention to cause some sort of harm. Misinformation is usually propagated without intention to cause harm. However, disinformation can be transformed into misinformation (when deliberate falsehood originally propagated to deceive is received by another person as truth and innocently propagated further)...\"(Omoregie, 2023)."
  },
  {
    "label": "Information Ethic",
    "type": "Class",
    "description": "\"Treats 'the world of data, information, and knowledge, with their relevant life-cycles, as a new environment, the infosphere, in which human beings, as informational organisms, may be flourishing.'\"",
    "provocation": "How many layers of reduction are required before we arrive at a common denominator between the self and the other?",
    "references": "\"... Information Ethics (IE), the philosophical foundational counterpart of CE, can be seen as a particular case of ‘environmental’ ethics or ethics of the infosphere. What is good for an information entity and the infosphere in general? This is the ethical question asked by IE. The answer is provided by a minimalist theory of deserts: IE argues that there is something more elementary and fundamental than life and pain, namely being, understood as information, and entropy, and that any information entity is to be recognised as the centre of a minimal moral claim, which deserves recognition and should help to regulate the implementation of any information process involving it....From an IE perspective, the ethical discourse now comes to concern information as such, that is not just all persons, their cultivation, well-being and social interactions, not just animals, plants and their proper natural life, but also anything that exists, from paintings and books to stars and stones; anything that may or will exist, like future generations; and anything that was but is no more, like our ancestors. Unlike other non-standard ethics, IE is more impartial and universal – or one may say less ethically biased – because it brings to ultimate completion the process of enlargement of the concept of what may count as a centre of moral claims, which now includes every instance of information, no matter whether physically implemented or not...\"\"(Floridi, 1999). \"\"...In taking a centrist approach, these different ethical theories (of which IE would presumably be the final and ultimate form) endeavor to identify what is essentially the same in a phenomenal diversity of different individuals. Consequently, they include others by effectively stripping away and reducing differences. This approach, although having the appearance of being increasingly more inclusive, effaces the unique alterity of others and turns them into more of the same...\" (Gunkel, 2017)"
  },
  {
    "label": "Intelligence As Emergent",
    "type": "Class",
    "description": "Refers to the idea that intelligence is not innate or unique to humans but emerges in relations and varies from actor to actor.",
    "provocation": "What unaccounted possibilities concerning ethical human-machine relations and emergent intelligence are immanent in the design of the AI system?",
    "references": "\"... there is a need for an interdisciplinary mode of theorising ‘intelligence’ as relational and affective in ways that can accommodate the fragmentation of both conceptual and material boundaries between human and AI, and human and machine. Our aim in investigating these sociological, philosophical and ethical questions is primarily to explore the relationship between affect, relationality and ‘intelligence,’ the intersection and integration of ‘human’ and ‘artificial’ intelligence, through an examination of how AI is used across different dimensions of intelligence... how ‘intelligence’ is ultimately conveyed, understood and (technologically or algorithmically) configured in practice through emerging relationships that go beyond the conceptual divisions between humans and machines, and humans vis-à-vis artificial intelligence-based technologies...AI has been described as “the science and engineering of making intelligent machines” McCarthy (2007: 2) or “the activity devoted to making machines intelligent” (Nilsson 2009: 13). Such definitions raise questions around what ‘intelligence’ itself entails. The word implies a philosophical and cultural fascination with intelligence as a characteristic capacity that seemingly confers on humans a special place among other life forms. The notion of ‘artificial intelligence’ suggests that intelligence can be simulated through technological means, and yet that such simulated intelligence remains different from the ‘natural’ or, perhaps, ‘real’ intelligence exhibited by humans...\" (De Togni et al., 2021)."
  },
  {
    "label": "Inter/non Governmental",
    "type": "Class",
    "description": "An entity created by a treaty, involving two or more nations, to work in good faith, on issues of common interest.",
    "provocation": "How does AI for social good carry forward the previous concerns and sensibilities vis-à-vis the discourse of development and third world?",
    "references": "\"\"\"...The institutionalization of development\ntook place at all levels, from the international organizations and national\nplanning agencies in the Third World to local development agencies,\ncommunity development committees, private voluntary agencies, and nongovernmental\norganizations. Starting in the mid-1940s with the creation of\nthe great international organizations, this process has not ceased to spread,\nresulting in the consolidation of an effective network of power. It is through\nthe action of this network that people and communities are bound to specific\ncycles of cultural and economic production and through which certain behaviors\nand rationalities are promoted. This field of intervention relies on\nmyriad local centers of power, in turn supported by forms of knowledge that\ncirculate at the local level...\"\"(Escobar, 2012)\""
  },
  {
    "label": "Interview and Survey",
    "type": "Class",
    "description": "A type of quantitative_qualitative method in which a researcher conducts structure, semi-structured or unstructured interviews with a representative sample of individuals or entities which is then collected and  analysed.",
    "provocation": "What do interview or survey results tell us?",
    "references": "\"...The interview is itself a social encounter. Interview-derived narratives and accounts are performances in their own right. They are, or contain embedded within them, speech events. They contain stories that reflect common genres. They construct biographies and identities. They deserve attention from those analytic perspectives. ...We cannot approach interview data simply from the point of view of ‘truth’ or ‘distortion’, and we cannot use such data with a view to remedying the incompleteness of observations. By the same token, we cannot rely on our observations in order to correct presumed inaccuracies in interview accounts. On the contrary, interviews generate data that have intrinsic properties of their own. In essence, we need to treat interviews as generating accounts and performances that have their own properties, and ought to be analysed in accordance with such characteristics...\" (Atkinson, 2015). \n\n\"...The Problem with survey research is that answers to questions are not reliable. When academic researchers, asking businesses, consultants,government agencies, newspaper reporters, inquiring citizens, and all others relying on the asking method, only have answers to questions it's impossible for them-or anyone else-to know if the answers correspond to what's really going on (Category One Answers) or do not (Category Two Answers). The only way to know if an answer is correct or accurate is to check, or verify, it with information from one or. preferably, two or more non-asking sources of information; say, from observation, experimentation, and documents. Those who rely on asking method--askers--do not have information from non-asking sources and, therefore, are not able to discern which, if any, answer is correct or incorrect. All survey researchers have is The Problem: all they have is unreliable information...Survey researchers do not accept these definitions of \"unreliable\" and\"\"reliable\". They contend asking produces reliable information to the extent it produces consistent, reproducible, results or scores. But this notion of reliability may just represent everyone obtaining \"\"the same wrong answer\"\" 3. To repeat: When all you have are answers to questions, you can't tell if they're right (Category One Answers) or wrong (Category Two Answers). When all you have are answers, all you have is The Problem...\"\" (Beam, 2012).\""
  },
  {
    "label": "Justice",
    "type": "Class",
    "description": "Fair and equitable treatment of individuals and groups in the development, deployment, and impact of artificial intelligence systems.",
    "provocation": "What is the relationship between justice and code(law)? Is justice possible without law? Can justice be coded?",
    "references": "\"...justice can become a verb. It then designates a way of being, of shining forth, of radiating, and of acting, a way of doing things, most often with words, with the performative force of a speech act: to justice. To justice would be to produce justice, cause it to prevail, make it come about, as an event, but without instrumentalizing it in a transitivefashion,without objectifying it, but rather making it proceed from itself even as one keeps it close itself, to what one is, namely just, closest to what one thinks, says, does, shows, and manifests. The one who thus justices does not refer in the first or the last place to the calculable rules and norms of law. He is just by essence, just as he breathes. He does what is just, he accomplishes the just in a spontaneous manner\" (Derrida, 2005). \"Some people work seriously on a kind of robotisation of justice: eventually, codes are only algorithms and judges need to follow them, so why not augmenting the impartiality, the speed and the efficiency in automatising justice decisions? It is already taking place. For instance, there are systems of recommendations in relation to early release for defendants or to evaluate risks of second offence. These are built on behavioural models founded on the analysis of Big Data, using profiles of typical second offenders. It is of course extremely tempting to follow such systems of recommendations for a judge or for someone who has to decide whether to keep someone in prison or to release him or her. If we deviate from these recommendations, if we decide against the machine’s position, we take personally the responsibility of a possible second offence. Perhaps there is some progress made on a specific notion of objectivity, but we can also lose something in the understanding of justice (that is particularly important in my opinion) as an undecidable horizon...\" (Rouvroy & Stiegler, 2016)."
  },
  {
    "label": "Legal Compliance",
    "type": "Class",
    "description": "Adherence of artificial intelligence systems and their developers, users, or operators to relevant laws, regulations, and standards governing AI technology.",
    "provocation": "How does the existing law shape or reshape what's considered an ethical AI?",
    "references": "\"...For example, the fact that the AMS algorithm differentiates according to an unemployed person’s education will, in the following typology, not be viewed as an undesired differentiation, because one’s status of education is not a feature that is protected by anti-discrimination law (Lopez, 2019). A differentiation on the basis of an unemployed person’s gender entry with potentially harmful effects, on the other hand, is viewed as undesirable, because the applicable Austrian anti-discrimination law protects the feature gender. Algorithmic systems are, thus, viewed as being situated in their respective national legal context and context of use...Another issue with legal frameworks is that they are always embedded in their national (or supra-national) context. Accordingly, applying the typology proposed in this paper always follows the national legal context in which the algorithmic system in question operates. Algorithmic systems and their potentially harmful effects on vulnerable individuals and groups have to be viewed as situated in their context of use—and this situatedness is as dynamic and ever-changing as legal regulations can be. In short, linking the bias typology to legal anti-discrimination regulations entails its own set of invisibilities...\"(Lopez, 2021)."
  },
  {
    "label": "Market Oriented",
    "type": "Class",
    "description": "Certain design motivations that rely on the market to asses needs and solutions.",
    "provocation": "Who benefits from the design? Is the design proprietary?",
    "references": "\"..call for responsible design was based on a clear opposition of this design approach to the more common and traditional market-oriented design, in which designers’ competences, technical knowledge, cultures, values and methodologies are finalized to produce a profit for companies operating on the market. Such design practice, ... is disregarding the above mentioned needs and increasing environmental problems and social unbalances...\" (Morelli, 2003)\""
  },
  {
    "label": "Material Semiotic Difference",
    "type": "Class",
    "description": "Differences among humans that are weaved together in both language and matter.",
    "provocation": "How do you see, feel, experience, and understand the world and its entanglement with the machine?",
    "references": "\"...Material semiotics is a set of tools and sensibilities for exploring how practices in the social\nworld are woven out of threads to form weaves that are simultaneously semiotic (because\nthey are relational, and/or they carry meanings) and material (because they are about the\nphysical stuff caught up and shaped in those relations.) It assumes that there is no single\nsocial structure or form of patterning because these material and social webs and weaves\ncome in different forms and styles. Instead its tools and sensibilities are used to explore a\nwide range of topics which include: how such processes of weaving are achieved or fail in\npractice; where those threads come from; their character, and what they exclude; their\nproductivity or performativity, including the ways in which they shape the elements that\nmake them up; the agendas that they carry; the multiplicity of the different realities that\nthey enact; how they interact, conflict with, or ignore one another; how they colonise or are\ncolonised by other webs; how they produce domination; and how such forms of domination\nmight be resisted...\"\"(Law, 2019)\""
  },
  {
    "label": "Matter of Concern",
    "type": "Class",
    "description": "Disputable, shifting, contested, controversial state of affairs.",
    "provocation": "Can we devise another powerful descriptive tool that deals this time with\nmatters of concern and whose import then will no longer be to debunk but\nto protect and to care, as Donna Haraway would put it? Is it really possible\nto transform the critical urge in the ethos of someone who adds reality to\nmatters of fact and not subtract reality?(Latour, 2005)",
    "references": "\"...A matter of concern is what happens to a matter of fact when you add to it its whole scenography, much like you would do by shifting your attention from the stage to the whole machinery of a theatre. Instead of simply being there,\nmatters of fact begin to look different, to render a different sound, they start to move in all directions, they overflow their boundaries, they include a complete set of new actors, they reveal the fragile envelopes in which they are housed. Instead of “being there whether you like it or not” they still have to be there, yes (this is one of the huge differences), they have to be liked, appreciated, tasted, experimented upon, mounted, prepared, put to the test. It is the same world, and yet, everything looks different. Matters of fact were indisputable, obstinate, simply there; matters of concern are disputable, and their obstinacy seems to be of an entirely different sort: they move, they carry you away, and, yes, they too matter...\" (Latour, 2014)."
  },
  {
    "label": "Matter of Fact",
    "type": "Class",
    "description": "Something that is known to have happened or to exist, especially something for which proof exists, or about which there is empirical information.",
    "provocation": "How many actors (human or nomhuman) are gathered to make AI systems exist as a matter of fact--as given and inevitable--and maintain that existence?",
    "references": "\"...The mistake we made, the mistake I made, was to believe that there was no efficient way to criticize matters of fact except by moving away from them and directing one’s attention toward the conditions that made them possible. But this meant accepting much too uncritically what matters of fact were... Reality is not defined by matters of fact. Matters of fact are not\nall that is given in experience... \"What is presented here is an\nentirely different attitude than the critical one, not a flight into the conditions of possibility of a given matter of fact, not the addition of something more human that the inhumane matters of fact would have missed, but,\nrather, a multifarious inquiry launched with the tools of anthropology,\nphilosophy, metaphysics, history, sociology to detect how many participants\nare gathered in a thing to make it exist and to maintain its existence...\" (Latour, 2005)."
  },
  {
    "label": "Matter of Interface",
    "type": "Class",
    "description": "The ways in which different objects interface--meet, connect, relate communicate--with each other.",
    "provocation": "How many layers of mediation and intermediation are involved that connect different actors in the making of an AI system?",
    "references": "\"...For questions regarding responsibility, forward-looking and backward-looking, it is important to clarify all these structural and temporal relations and interactions: not only the social interactions and roles of humans but also their interactions with things and the relations and interactions between things. In this sense, responsibility for technology is not only a matter of faces but also of interfaces...\" (Coeckelbergh, 2020)"
  },
  {
    "label": "Matters Of",
    "type": "Class",
    "description": "Different ways in which things relate to each other.",
    "provocation": "(To be updated)",
    "references": "(To be updated)"
  },
  {
    "label": "Method",
    "type": "Class",
    "description": "Strategy employed to gather, analyze, and interpret data or information in order to answer specific questions or investigate phenomena.",
    "provocation": "How do different methodological approaches capture the phenomenon and what can be known about it?",
    "references": "\"...It matters what matters we use to think other matters with; it matters what stories we tell to tell other stories with; it matters what knots knot knots, what thoughts think thoughts, what descriptions describe descriptions, what ties tie ties. It matters what worlds make worlds, what worlds make stories...” (Haraway, 2016) and it matters what methods we use to study the world around us.                \n\"...Science is an essentially anarchic enterprise: theoretical anarchism is more humanitarian and more likely to encourage progress than its law-and-order alternatives...For example, we may use hypotheses that contradict well-confirmed theories and/or well-established experimental results. We may advance science by proceeding counterinductively...\" (Feyerabend, 1993)"
  },
  {
    "label": "New Risks",
    "type": "Class",
    "description": "Type of risk that is as yet unaacounted for and there are not social, legal or political safeguards against it.",
    "provocation": "Do new risks also bring new potentialities for human-nonhuman relations?",
    "references": "\"...The emergent, unpredictable, non-linear and dynamic nature of materialist enactments is again emphasised in this literature, which builds on the work of many social theorists, including Spinoza, Foucault, Deleuze, Merleau-Ponty, Latour and Bourdieu. This approach also refuses a dualistic approach to agency and matter and focuses attention on the ways in which actors are inextricably entangled, together generating vitality (Bennett, 2004, 2010; Coole, 2013). Bennett’s concept of ‘thing-power’, or ‘the curious ability of inanimate things to animate, to act, to product effects dramatic and subtle’ (2004: 351) is important in emphasising the vibrant agential capacities of human–nonhuman assemblages. Thing-power is a dynamic flow of energy between and with the components of assemblages. Bennett argues that the concept of thing-power emphasises the intimacy of humans and nonhumans, the ways that they are so closely intertwined in the moments when ‘human being and thinghood overlap’ (2004: 349). She further elaborates that thing-power is not located in one specific object alone, but rather is a function of the grouping of different things in an assemblage, each operating in conjunction with the others (including humans) (Bennett, 2004: 354)...\" (Lupton, 2018). This thing power can always pose new risks and new potentialities."
  },
  {
    "label": "Non Discrimination",
    "type": "Class",
    "description": "An ethical parameter that ensures that individuals or groups are not discriminated against by the AI system.",
    "provocation": "What would happen if we took discrimination with regard to data-driven politics seriously and built systems that acknowledged the fundamental fluidity of identity?",
    "references": "\"What would happen if we took discrimination with regard to data-driven politics seriously and built systems that acknowledged the fundamental fluidity of identity?  In her essay, Hito Steyerl offers a taste of what this could mean. She shows us the hardwired ideologies of a machinic vision, in which data builds the basis of our reality. However, this reality doesn’t necessarily match with the catchphrases of the data industry. Rather than a smooth operation, algorithmically enhanced pattern recognition struggles with a massive amount of real—that is, dirty—data. As Steyerl explains, algorithms must constantly fix the mess that we call life. And just like in real life, the criteria to decide what to include and exclude are intrinsically political\" (Apprich et al., 2018)."
  },
  {
    "label": "Non Human",
    "type": "Class",
    "description": "All things, objects, entities, and processes which cannot be identified as human beings.",
    "provocation": "How do non-human entities enable or interrupt the AI system?",
    "references": "\"...Natural entities are not to be regarded, therefore, simply as\npassive intermediaries; they retain the ability to subvert the associations of the social thereby recasting associations in new ways. The lesson is clear: we should refrain from excluding natural entities from our analyses for such entities have the ability either to consolidate or to undermine the sets of associations that constitute human - nonhuman networks...\" (Murdoch, 1997)"
  },
  {
    "label": "Non Human Autonomy",
    "type": "Class",
    "description": "Non-human autonomy as an ethical parameter refers to the capacity or degree of independence and decision-making authority granted to artificial intelligence, robots, or autonomous systems, while considering their potential impact, constraints, and responsibilities in relation to human society and values.",
    "provocation": "Do we need a parliament of things?",
    "references": "\"...In the shadow of the coming catastrophe of semiocapital’s climate change and toxicity, do we need a parliament of things—a demogenesis fitting the simultaneity of soil, earth, and science (see Latour 2015)? Let’s leave aside the question of whether existence has agreed that its governance is like a human parliament. Are some things going to get more ballots, or more weight in the voting? Will we only allow those forms of entanglement that are our companion species to vote, excluding various forms of viruses, bacteria, and algae? Probably—this is the point of an antagonism defining the field of solidarity. And will the parliament of things include all things living and nonliving? Will desert sands get a vote? Or when we pass out the ballots will we predetermine what does and doesn’t have a soul, refusing the nonliving, the never-having-lived, a possibility of extending itself? Or do we decide that all things are vital? Do we work with those who say that from the perspective of anthropogenic climate change there is no difference between life and nonlife? ... But politics after anthropogenic climate change and toxicity will need to grapple with a world without autonomy or antagonists yet extraordinarily hostile to some regions of existence. The illusions of our epoch are the autonomous and antagonistic. Other illusions may be better suited. Viruses, gassings, toxins—these are the names we give to manners of appearing and spreading; tactics of diverting the energies of arrangements of existence in order to extend themselves; strategies of copying, duplicating, and lying dormant even as they continually adjust to, experiment with, and test their circumstances; maneuvers to confuse and level every difference that emerges between regions while carefully taking advantage of the minutest aspects of their differentiation...\" (Povinelli, 2017)"
  },
  {
    "label": "Not Listed",
    "type": "Class",
    "description": "An aspect of socio-technical system that is not part of this ontology.",
    "provocation": "(To be updated)",
    "references": "(To be updated)"
  },
  {
    "label": "Parent",
    "type": "Class",
    "description": "A parent is an individual who has given birth to or legally adopted a child and is responsible for their upbringing, care, and well-being.",
    "provocation": "How does datafication of education reshape parenting?",
    "references": "\"...More broadly, one can argue that the meaning of technology is subject to an ongoing process of social negotiation. Computers are not merely ‘consumables’ like many other products. They are also symbolic goods that serve as markers of social distinction (Cawson et al. 1995)...they are seen to represent modernity, intellectual superiority and freedom from constraint. From being the preserve of geeks and nerds, they are now increasingly represented as the epitome of cool sophistication. Here, again, education plays a crucial symbolic role. Investing in computers is, so parents are told, a way of investing in your children’s future. Computers give children access to worlds of knowledge that would otherwise be denied to them; and, so it is argued, they put children themselves in control of their own learning. Education and parenting without technology thereby become at least conservative, if not downright reactionary. It is the fundamental responsibility of good parents and teachers to ‘catch up’ with the children who are in their charge—although there is considerable room for debate about whether the promises here are actually fulfilled\" (Buckingham et al., 2013)... \"Up until to date, parents have only been able to participate to a limited extent in their children's school activities. Manolev et al. (this issue) however, describe how parents may receive daily updates on their child’s behaviour via the ClassDojo platform. This platform facilitates the interaction of different user groups such as teachers, students, parents and school management and in so doing expands the space of communication between educational actors and transforms their relationships. Bradbury (this issue), reports on the changing relationships of teachers and children but also parents and children through digital assessment practices that commence in early childhood education. She reports how reception teachers experience the need to produce data as ‘detrimental to the process of building relationships with children to make them feel secure’ (p. 15). The necessity to use tablet-based assessments changed the previous interaction and ‘reduced focus on building relationships’ (ibid). Parents however, having access to these assessment data become constant observers of their child’s ‘progress...’\" (Jarke & Breiter, 2019)."
  },
  {
    "label": "Participatory Design",
    "type": "Class",
    "description": "A type of qualitative research method that includes research subjects as participants to shape and have stakes in the knowledge output.",
    "provocation": "How can we make this relational commitment and accountability more widespread as a foundational practice in Computer-Supported Cooperative Work (CSCW) research when engaging with communities that are not our own?",
    "references": "\"...Moving towards a feminist approach to data engagement involves also considering the ways that we engage in our research practice. Harrington et al. suggest equitable participatory design as an ethical approach to community-based computing research with marginalized and vulnerable populations, extending the ways the HCI and CSCW community have discussed PD with these groups.  How can we make this relational commitment and accountability more widespread as a foundational practice in CSCW research when engaging with communities that are not our own? To explore this\nquestion, we address the following ongoing strands of CSCW and PD research: (1) Community-driven engagement (de-center researchers and ensure that those without institutional power drive inquiry and design); (2) Accountable positionality (begin by accounting for researcher’s privileges, roles, and\nresponsibilities); (3) Responsible citational practices (responsibly consider whose voices get amplified and credited); and (4) Maintaining transparency (put mechanisms in place to keep budgets, promises, and transactions open and trackable)...\" (D’Ignazio et al., 2020)."
  },
  {
    "label": "Paternalist",
    "type": "Class",
    "description": "A form of decision-making or governance in which an authority figure or organization makes choices or enforces policies on behalf of others, believing that it is for their own good. Paternalism often involves restricting individual autonomy or freedom to protect individuals from harm, even if they may not agree with or prefer those decisions.",
    "provocation": "Is the design motivated by an assumption that the user doesn't know rather than exploring what the user knows?",
    "references": "\"...On the other hand, these global practices of care are also entangled with acts of control. Peacebuilding, public health, emergency aid, human rights, and development are expressions of this tension between care and control. There is a concept that captures this tension: paternalism. Drawing on our moral intuitions, I argue that paternalism is the attempt by one actor to substitute his judgment for another actor's on the grounds that such an imposition will improve the welfare of the target actor. After discussing and defending this definition, I note how our unease with paternalism seems to grow as we scale up from the interpersonal to the international, which I argue owes to the evaporation of community and equality...\" (Barnett, 2015)."
  },
  {
    "label": "Personal Non Personal",
    "type": "Class",
    "description": "Data categories in GDPR that distinguish between personal and nonpersonal data. Personal data directly or indirectly relates to an identified or identifiable natural person. Non-personal data is all data which cannot be linked to an identifiable natural person.",
    "provocation": "How is the category of personal or non-personal data being interpreted? Can the non-personal, anonymized data be re-identified in future? Are there possible violations of individuals or groups that ae possible through non-personal data?",
    "references": "\"...The GDPR only applies to personal data, meaning that non-personal data falls outside its scope of application. The Regulation adopts a binary approach \"which is limiting\" because where \"some data can be anonymous data from the beginning (such as climatic sensor data with no link to natural persons), other data may at some point be personal data but then be successfully manipulated to no longer relate to an identified or identifiable natural person. This underscores that the classification of personal data is dynamic. Depending on context, the same data point can be personal or non-personal and hence be subject to the Regulation or not. It is important to remember that ‘the risk of reidentification through data linkage is essentially unpredictable because it can never be assessed with certainty what data is already available or what data may be released in the future...\" (Finck & Pallas, 2020)"
  },
  {
    "label": "Philanthrocapitalist",
    "type": "Class",
    "description": "Financial contributions or donations provided by individuals, organizations, foundations, or corporations to support charitable, social, educational, cultural, or humanitarian causes.",
    "provocation": "What kind of value does the funder generate through their investment in AI4SG systems? Does philanthrocapitalism represent a new market strategy for profit augmentation, a new form of charitable giving, or a revolutionary combination of both?",
    "references": "\"...In 2006, an article in the Economist magazine introduced the term ‘‘philanthrocapitalism’’ to describe a trend sweeping philanthropic institutions: the tendency for a new breed of donors to conflate business aims with charitable endeavors, making philanthropy more cost-effective, impact-oriented, and financially profitable. Underpinning the rise of philanthrocapitalism is the idea that to do good socially, one must do well financially: public and private interest are strategically conflated and touted as intrinsically mutually compatible. I suggest that far from being a new concept, the deliberate conflation of public and private interest resonates with eighteenth-century perceptions of the moral value of capitalism: the debatable view that capitalism helps to mitigate political strife and foster cooperation among nations, promoting the public good through individual economic enrichment...\" (McGoey, 2012)."
  },
  {
    "label": "Policy Maker",
    "type": "Class",
    "description": "An individual or entity responsible for shaping, developing, and implementing educational policies, regulations, and initiatives that impact educational institutions, practices, and systems.",
    "provocation": "How are policies translated across different contexts?",
    "references": "\"...five strategic perspectives are recommended for promoting policy learning. (1) Resisting temptation to ‘borrow’ policies or ‘best practices’ from other countries without adapting to fit local conditions (Nielsen and Serban 2012; Raffe 2011). Though awareness of international trends and good practice is important, experience indicates that it is short-sighted to think that arrangements in one country can be easily replicated in another. Instead, national policy makers must engage with local stakeholders, including industry, regional and district managers, head teachers, teachers, parents, community representatives and others, to discuss what policies are required, how goals should be framed, and what implementation strategies should be devised to take account of local conditions and circumstances. Such policy learning can result in the development of thoughtful digital education policies capable of flexible delivery in unique organizational contexts, sensitive, for example to linguistic and other cultural factors that, if not addressed could undermine the goal of achieving uniformly high levels of digital literacy for all students and communities...\" (Zagami et al., 2018)."
  },
  {
    "label": "Postcolonial Ethic",
    "type": "Class",
    "description": "Postcolonial ethics is a moral framework that addresses the ethical implications of colonial histories, emphasizing decolonization, cultural respect, and justice in the aftermath of colonialism.",
    "provocation": "How does AI4SG shape new relations of coloniality?",
    "references": "\"...postcolonialism is more than just a condition. \"Postcoloniality\" is a perspective on continuity; a \"salutary reminder of the persistent 'neo-colonial' relations within the 'new'world order and the multinational division of labor.\" Beyond that is \"postcolonial critique\" - a mode of inquiry that bears witness to\nthose hybrid \"cultures of a postcolonial contra-modernity\" that challenge nationalist conceptions of history and community. This recalls Edward Said on \"the role of the postcolonial intellectual,\" which is \"to clarify and expand upon experiences of colonialism which continue into the present...\"(Manzo, 1997)"
  },
  {
    "label": "Prospective Transparency",
    "type": "Class",
    "description": "Prospective transparency informs users about the data processing and the working of the system upfront. It describes how the AI system reaches decisions in general. Thus, prospective transparency can be seen as an accountability mechanism (Zerilli et al., 2018).",
    "provocation": "(To be updated)",
    "references": "(To be updated)"
  },
  {
    "label": "Qualitative and Qualitative",
    "type": "Class",
    "description": "Qualitative research, as defined here, is consequently a combination of two criteria: (i) how to do things –namely, generating and analyzing empirical material, in an iterative process in which one gets closer by making distinctions, and (ii) the outcome –improved understanding novel to the scholarly community. (Aspers & Corte, 2019). Quantitative: Emphasize objective measurements and the statistical, mathematical, or numerical analysis of data collected through polls, questionnaires, and surveys, or by manipulating pre-existing statistical data using computational techniques. Quantitative research focuses on gathering numerical data and generalizing it across groups of people or to explain a particular phenomenon.",
    "provocation": "What good is polarizing research into qualitative and quantitative?",
    "references": "\"...A polar distinction is commonly used to describe and produce different kinds of research:  quantitative versus qualitative...Philosophers of quite different ilk (e.g., Hegel, 1977; Husserl, 1968) agree that the material world has both quantitative (continuous) aspects—for example, temperature variation within a liquid—and dis-continuous (qualitative) aspects—...\" (Ercikan & Roth, 2006)"
  },
  {
    "label": "Question",
    "type": "Class",
    "description": "An inquiry presented to seek information, clarification, or a response from someone.",
    "provocation": "What does it mean to ask?",
    "references": "\"..Asking, or asking for, almost anything, whether directions, help, love, money, even for the time, can be asking for trouble, so we must take a great deal of trouble with the way we ask in order to head it off...making a request may be a ‘facethreatening action’, that potentially threatens the freedom of action of one’s interlocutor. Asking anything of anyone is requesting a gift or benefit that they do not have to give... one must avoid giving the impression that one assumes any right to what one requests, while securing nevertheless one’s right to make the request. ...Asking is difficult not just because asking may seem like an aggressive imposition. For asking is an intimate act, or an act which intimates intimacy, which can be uncomfortable even where it is not aggressive....Asking any kind of question always sings, like the Mock Turtle, ‘Will you, wo’n’t you, will you, wo’n’t you, wo’n’t you join the dance?’ (Carroll 1998, 90). Requesting or enquiring are both forms of requirement: if any asking simultaneously asks about the acceptability of its asking, it also asks its subject to agree to give an answer, whatever the content of that answer might be. Asking is therefore always attended by moral, emotional and political tension. Asking is difficult because of our awareness that being asked can be what we call an imposition, in that it imposes a demand; that any ask is potentially a big ask...\" (Connor, 2023)"
  },
  {
    "label": "Redefined Ethical Parameter",
    "type": "Class",
    "description": "Ethical parameters that have been redefined from relational perspectives.",
    "provocation": "(To be updated)",
    "references": "(To be updated)"
  },
  {
    "label": "Relational Approach",
    "type": "Class",
    "description": "Ethical parameters that have been redefined from relational perspectives",
    "provocation": "Can socio-technical designs pivot up on contingencies of relations, ideas, values and priorities?",
    "references": "\"...Neither people, nor the environment, are static; what society deems fair and ethical changes over time. The concept of fairness and ethical practice is, therefore, a moving target and not something that can have a final answer or can be “solved” once and for all. It is possible that what is considered ethical currently and within certain domains for certain societies will not be received similarly at a different time, in another domain, or for a different society . Adopting relational ethics means that we view our understandings, proposed solutions, and definitions of “bias”, “fairness” and “ethics” as partially-open [and always open to redefinition]. This partial openness allows for revision and reiteration in accordance with the dynamic development of such challenges...\" (Birhane, 2021)"
  },
  {
    "label": "Relational Ethic",
    "type": "Class",
    "description": "An ethical framework that centres relations between actors as site of ethical contestation and deliberation.",
    "provocation": "How are emergent relations accounted for in the design?",
    "references": "\"..Relational ethics, at its core, is an attempt to unravel our assumptions and presuppositions and to rethink ethics in a broader manner via engaged epistemology in a way that puts the needs and welfare of the most impacted\nand marginalized at the center...\" (Birhane et al., 2022)\""
  },
  {
    "label": "Relevance",
    "type": "Class",
    "description": "Consideration of the importance, significance, and appropriateness of information, decisions, or actions within a specific context. It ensures that ethical choices and actions are well-suited to address specific needs and concerns, promoting effectiveness and fairness.",
    "provocation": "How to come to terms with the events by which, in given situations, things of a diverse nature become relevant in specific ways? As a question, that is, of how\nthey come to matter.",
    "references": "\"...'Relevance’ has become so ubiquitous and multifarious a demand, it has become such a ‘tyranny’—as political scientist Matthew Flinders (2013) has recently put it—that it has failed to raise any substantial, conceptual investigation on what it itself might involve. Enforced by some and dismissed by others, the notion of ‘relevance’ has become something of an empty placeholder that heralds an ideal solution to general, anonymous, and pre-existent problems. A solution, moreover, whose conditions of success are said to be defi nable in advance, thus turning ‘relevance’ into an abstract criterion of demarcation...to take the notion of relevance seriously—beyond its tyrannic demands—will require that we cease proposing ‘relevance’ as a new imposed criterion of judgement, in order to follow the requirements that ensue from its conception as a speculative and practical problem...\" (Savransky, 2016)."
  },
  {
    "label": "Respects Privacy",
    "type": "Class",
    "description": "An ethical parameter that refers to the extent to which AI systems safeguard individuals' personal information, uphold their confidentiality, and ensure that data handling and processing align with established privacy norms, laws, and user consent.",
    "provocation": "Is there an option to say no?",
    "references": "\"It is already a common critique that current forms of notifications (privacy policies and terms of services followed by binary “agree” or “disagree” buttons) used to acquire our consent in digital platforms have turned it into meaningless and nongranular ways to accept different data processing operations. But critiques from feminist scholars to the model of “notice and consent” go even deeper and question structural power asymmetries between data subjects and the controller, as well as the neoliberal individualistic approach that data protection legislations have set towards consent. For legal scholar Julie E. Cohen, to understand privacy simply as an individual right is a mistake, as she points out, “the ability to have, maintain and manage privacy depends heavily on the attributes of one’s social, material, and informational environment” (2012). In this way, privacy is not a thing or an abstract right, but an environmental condition that enables situated subjects to navigate within preexisting cultural and social matrices (Cohen, 2012, 2018)... For researcher Daniel Solove (2013), under the current approach of privacy regulation—that he would call “privacy self-management”, but is also called “privacy as control” by other scholars (Cohen, 2018)—policymakers try to provide people with a set of rights to enable them to make decisions about how to manage their data. This is an individual framing of consent, based on the assumption that we are all autonomous, free, and rational individuals with the capacity to consent, disregarding our possibility of doing so due to unequal power dynamics\"(Varon & Peña, 2021)."
  },
  {
    "label": "Responsibility",
    "type": "Class",
    "description": "The obligation of individuals, organizations, and developers involved in AI technologies to act ethically, transparently, and accountably throughout the AI lifecycle.",
    "provocation": "What does it mean to be responsible?",
    "references": "\"...To be accountable; answerable. Put differently, it is the ability to answer when called. From the Latin respondere, ‘to respond’. Bound up in the term is a notion of responsibility as responsiveness: ethics borne of situated response, ethics enacted in the pulse and pause of attentiveness. And yet this bristles against more commonly held notions of responsibility as the very opposite: to be held to account, to be judged according to fixed and clear terms. Indeed, to characterise responsibility as responsiveness might arguably invite irresponsibility. To discern the course of proper action, to evaluate the ethical implications of a given encounter, we must have a clear sense of the terms, must we not? My wager here is that in the context of engagement across social difference, this traditional conception of responsibility as ‘fixed in place’ can itself prove irresponsible insofar as it fails to account for the complexity, dynamism and interrelation of identity and encounter. In its place, I offer an alternative account of responsibility as responsiveness—what I will call a dispositional ethics. An ethics of encounter across social difference must provide the means to acknowledge and appropriately respond to what by definition exceeds one’s terms of knowing and valuing the world. As such, it concerns a sensibility and an art of listening to what appears first as white noise. Responsibility, in this light, is thus necessarily conceived in affective rather than epistemological or metaphysical terms, where to be responsible is to remain receptive and responsive within the encounter, despite the challenges it might present to our worldview\nand implication of our role within it...\" (Beausoleil, 2015)\""
  },
  {
    "label": "Responsiblity As Responseability",
    "type": "Class",
    "description": "Learn how to respond and what respond in the case of (non-human) means.",
    "provocation": "What does it mean to respond?",
    "references": "\"\"\"...our understanding of performativity and responsibility as not confinable to the human subject: “Responsibility is not ours alone. […] Responsibility entails an ongoing responsiveness to the entanglements of self and other, here and there, now and then” (Barad, 2007, p. 394). Responsibility and\naccountability are thus opened to reworking; the central connotation is no longer an imperative of taking charge and giving reasons but, rather,\nan ability to respond to “others”. Responsibility is re-imagined as an ethical injunction to work on the ability to respond to “others”, to take care of the entanglements of our relationalities — and this implies that response-ability is tied to processes of becoming different in/through the response. This notion of responsibility implies a solidarity that is not based on proximity and similarity but on being-in-this-together...\"\"(Meissner, 2014)\""
  },
  {
    "label": "Retrospective Tranparency",
    "type": "Class",
    "description": "\"Retrospective transparency, on the other hand, refers to post hoc explanations and rationales (Paal and Pauly, 2018). Retrospective transparency includes the notion of inspectability and explainability”",
    "provocation": "(To be updated)",
    "references": "(To be updated)"
  },
  {
    "label": "School",
    "type": "Class",
    "description": "A type of educational institution that provide learning spaces and learning environments for the teaching of students under the direction of teachers.",
    "provocation": "How might schools and other educational institutions adopt and adapt technologies which are not designed for profitability, efficiency and growth, but instead orient toward de-growth, and to more equitable, participatory, democratic, interrelated and ecological societies?",
    "references": "\"...Administrator roles also come into play. In the 1990’s, when interest in technology was beginning to burgeon in schools, Radlick (1998) noted that superintendents were largely withdrawn from procurement discussions, suggesting the risk of “grassroots” decisions being made in the absence of broader strategic planning. However, concerns have been raised about principals lacking instructional technology (IT) leadership skills sharing IT decisions with often similarly inexperienced teachers and other staff (Dexter 2008; Flanagan and Jacobsen 2003). The rapid growth of ed-tech products can only exacerbate the frustration and confusion with developing viable school-wide and classroom-based IT plans...\" (Morrison et al., 2019)"
  },
  {
    "label": "Socio Technical System",
    "type": "Class",
    "description": "What appears to be social is partly technical. What we usually call technical is partly social. In practice nothing is purely technical. Neither is anything purely\nsocial. And the same may be said for the economic, the political, the scientific, and all the rest.",
    "provocation": "Where does social begin and technical end?",
    "references": "\"...But there is also a sense in which, despite the pioneering work on sociotechnical systems by the Tavistock group in the 1960s,22 technology does not appear to be productively integrated into large parts of the sociological imagination. Since Foucault, we have no difficulty in inscribing texts on bodies, or\nconstituting agents discursively. But (with a few notable exceptions)23 it does not occur to us to treat machines with the same analytical machinery as people. The problem has something to do with the absence of a method for juggling simultaneously with both the social and the technical. Sociologists, I want to say, tend to switch registers. They talk of the social. And then (if they talk of it\nat all which most do not) they talk of the technical. And, if it appears, the technical acts either as a kind of explanatory deus ex machina (technological determinism). Or it is treated as an expression of social relations (social reductionism). Or (with difficulty) the two are treated as two classes of objects which interact and mutually shape one another...\" (Law, 1990)"
  },
  {
    "label": "Solve Social Problem",
    "type": "Class",
    "description": "A type of design-motive that prioritizes soliving one particular social problem with the help of an AI system.",
    "provocation": "What exactly is the problem?",
    "references": "\"...Eugeny  Morozov castigates the products of silicon valley and many academic research  labs  for  providing  solutions  to  problems  that  do not  exist  or  prototyping  reductive “silver  bullet”  solutions for  complex  social,  political  and  environmental  problems [31].  He  takes  the  term  “solutionism”  from  Michael Dobbins’s 2009 book  “Urban Design and People” [16]. As HCI begins  to address the  development of  “smart  cities”  it is  increasingly  important  to engage  with solutionism  as it relates  to  urban and  city  planning.  Dobbins  argues  that “solution-driven  design”  generally  reaches  for  answers before questions have been asked fully...\" (Blythe et al., 2016)"
  },
  {
    "label": "Speculative Ethic",
    "type": "Class",
    "description": "A type of ethical framework that moves away from 'if, then' ethical framing to 'what, if' focussing on how human-nonhuman relations are formed and contested in everyday.",
    "provocation": "What conditions of possibility does an AI system create?",
    "references": "\"...speculative ethics...then implores us to ask grounding questions when it comes to algorithmi-cally powered prediction tools.... Such questions would include: Where are these tools and pathways situated—in whose perspectives and contexts, in which kind of data and research, in what kind of knowledge traditions? What is the ground from which this prediction is being made (which material conditions, institutional settings, data sources, etc.) and what conditions of possibility does it create because of that? Who are the anticipated benefactors of the use of such tools and, importantly, who are not included in the stakeholders list? Asking these contextual questions also requires endorsing a more systemic understanding of ... care and prediction, as a complex nexus of relations that are dependent not only on strictly defined categories but also on a much broader set of factors such as quality of life, social support network, structural in/equalities, and so on. The challenge ...that we raise for practitioners is to do this with an understanding of the biases that are built into and the limitations of algorithmic decision making. On a more theoretical level, this also encourages to re‐think and expand the premises of ethical actions and decisions, particularly in the face of technological and other forms of difference...\" (Smith et al., 2023)."
  },
  {
    "label": "Student and Learner",
    "type": "Class",
    "description": "A student or learner refers to a person partaking in the process of acquiring new knowledge, skill. Today this most often takes place within a formal setting of educational institutions or informal settings of coaching institutes and edtech platforms or anywhere on the web.",
    "provocation": "Is the student treated as a consumer or a person seeking to acquire new dispositions of mind and body?",
    "references": "\"...A real learner is a producer, not a consumer, of the knowledge he or she gains. As research has repeatedly shown, active learners grow while passive learners barely remember the facts long enough to regurgitate them on a test. The learner joins the teacher and the other students in the class as part of the management and production staff of one’s own learning process in constructing knowledge. As part of the management and production staff of their own learning process, students must take responsibility for their own learning. Therefore, learning is a direct result of the student’s efforts rather than a service that the student purchases...\" (Groccia, 1997)"
  },
  {
    "label": "Surveillance",
    "type": "Class",
    "description": "A type of harm that can result in extensive, invasive, or unwarranted monitoring, data collection, and tracking of individuals or groups, potentially leading to privacy violations, discrimination, and social control.",
    "provocation": "What is (not) to be done?",
    "references": "\"...Types of machines are easily matched with each type of society--not that machines are determining, but because they express those social forms capable of generating them and using them. The old societies of sovereignty made use of simple machines--levers, pulleys, clocks; but the recent disciplinary societies equipped themselves with machines involving energy, with the passive danger of entropy and the active danger of sabotage; the societies of control operate with machines of a third type, computers, whose passive danger is jamming and whose active one is piracy or the introduction of viruses....The conception of a control mechanism, giving the position of any element within an open environment at any given instant (whether animal in a reserve or human in a corporation, as with an electronic collar), is not necessarily one of science fiction. Félix Guattari has imagined a city where one would be able to leave one's apartment, one's street, one's neighborhood, thanks to one's (dividual) electronic card that raises a given barrier; but the card could just as easily be rejected on a given day or between certain hours; what counts is not the barrier but the computer that tracks each person's position--licit or illicit--and effects a universal modulation....Many young people strangely boast of being \"motivated\"; they re-request apprenticeships and permanent training. It's up to them to discover what they're being made to serve, just as their elders discovered, not without difficulty, the telos of the disciplines...\"(Deleuze, 1992)"
  },
  {
    "label": "Teacher and Educator",
    "type": "Class",
    "description": "A teacher or an educator imparts knowledge or instructs in a classroom. The are also often involved in various other decision making of educational organisations and institutions across various scales and in various capacities from the classroom to the world.",
    "provocation": "How are teachers and educators involved in the decision-making to use and deploy AI systems?",
    "references": "\"...Discouragingly, however, prior research suggests very limited teacher involvement in the procurement of educational products. As experts have long observed, however, the involvement of end-users in the decision-making process fosters successful implementation of an intervention ...\" (Morrison et al., 2019)."
  },
  {
    "label": "Technocracism",
    "type": "Class",
    "description": "Technocracism appears as a strategy for solving all problems of humanity with the help of techniques and technologies, as well as the appropriate ideology that justifies and distributes this strategy in society.",
    "provocation": "What social function is assigned to the machine?",
    "references": "\"Technocracism appears as a strategy for solving all problems of humanity with the help of techniques and technologies, as well as the appropriate ideology that justifies and distributes this strategy in society. ...It   is   not   necessary   to understand   technology   too   technically-narrowly. This   leads   to   technocracism  of  thinking  and  culture,  attempts  to  engineeringly  comprehend  the  humanistic  reality of public existence. On the other hand, it is no less dangerous to idealize technology too much, giving it an overly expanded humanitarian significance, when almost the entire culture is not  so  much  the  result  of  applying the technology  stack, as  it  is  directing technologies on ran-domly  selected  humanistic  goals.  It  is  between  these  Scylla  and  Charybdis,  where  the real significance of technology in society is located...\"(Boichenko, 2021)"
  },
  {
    "label": "Technology Company",
    "type": "Class",
    "description": "A tech company, short for technology company, is an organization that primarily focuses on developing, manufacturing, or providing products, services, or solutions related to information technology, electronics, software, or other advanced technologies, often for commercial purposes and innovation-driven markets.",
    "provocation": "How does the techno-economic configuration of Big Tech constitute and is constituted by the broader ecosystem of technoscience and political economy?",
    "references": "Big Tech is in the public and political spotlight. Usually defined as Apple, Amazon, Microsoft, Google/Alphabet, and Facebook/Meta, Big Tech is becoming the watchword for corporate surveillance, monopoly, and market power.Footnote1 Arguably, they are the defining institutions of our day, dominating our political economies, societies, and polities as Big Oil or Big Banks did in their time. Criticism of Big Tech is increasingly evident as well...commentators have highlighted the significant loss of trust in these digital technology companies and their wares – dubbed the ‘techlash’ (Foroohar, Citation2019). This techlash is hardly surprising since, as Prainsack (Citation2019) points out, Big Tech firms increasingly underpin much of our social, political, and economic worlds by providing the digital infrastructure on which we rely to live our lives. Consequently, governments and others around the world are increasingly turning their regulatory gaze onto Big Tech, leading to a surge in policy and legislative measures to curb their social and market power...While each paper describes the power (and power inequity) of Big Tech, many highlight the unstable nature of this power, or as Balzam and Yuran (Citation2022) put it, the ‘fragility’. Many of the papers complicate facile notions of how Big Tech firms wield power, showing it is sometimes done in cooperation with non-obvious actors like state regulators or even critical academics qua corporate ethicists\"(Birch & Bronson, 2022)."
  },
  {
    "label": "Think Tank",
    "type": "Class",
    "description": "A think tank is a policy institute undertaking research and advocacy on social policy, political strategy, economics, military, technology, and culture.",
    "provocation": "How do think tanks influence the policy process?",
    "references": "\"...Thus, think-tank intellectuals are not philosophers or ‘orators’ of ‘grand narratives’ – these are Gramsci’s ‘traditional intellectuals’ (Gramsci, 1971: 5) – but are concerned with policy details and politics. Think-tank analysts are best defined as part of the network of ‘organic intellectuals’ of capitalism among whom civil servants, technicians, policy experts or legal experts can also be found. They are ‘permanent persuaders’ (Gramsci, 1971: 334) and fulfil technical, directive and organizational needs of society (Showstack Sassoon, 1980). Based on such an understanding, Georgina Murray and Douglas Pacheco (2000) argued that think-tanks have fulfilled a role as gatekeepers in the survival of advanced capitalism which partly rests on its ability to legitimize itself discursively in cultural, moral, ethical and intellectual spheres. Other neo-Gramscians analysed think-tanks as one actor among many in the discursive (re)production of the hegemony of neoliberalism or Keynesianism (e.g. Blank, 2003; Desai, 1994; Gamble, 1989; Overbeek, 1990)...Think-tanks, in their different and changing organizational expressions, will continue to play a role in the cooperative networks of societies with increasing need for professionalized expertise.\"(Pautz, 2011)"
  },
  {
    "label": "Threat to Privacy",
    "type": "Class",
    "description": "A type of harms that poses a threat to person's personal data.",
    "provocation": "(To be updated)",
    "references": "\"...Several recent studies have suggested that the highly publicized controversies concerning dataveillance and data breaches have begun to influence people’s attitudes to the ways in which digital data are routinely collected on them and used by second and third parties. Two Pew reports outlining the findings of surveys about Americans’ attitudes to data privacy (Pew Research Center, 2014; Madden and Rainie, 2015) found that the respondents were aware of many aspects related to how their privacy was being challenged, and of data security breaches, including national security agencies’ dataveillance of citizens and how their personal information is used by commercial companies. The first report (Pew Research Center, 2014) found that nearly all of the respondents were aware of Snowden’s documents and what they revealed about the surveillance of citizens. They felt that their privacy was under threat by such surveillance and that conducted by commercial internet organizations. Nearly all of the respondents agreed that people had lost control over how their personal information is collected and used by companies...While people may be aware of the more invasive or overt forms of dataveillance to which they are subjected (such as targeted marketing and advertising or CCTV cameras), there is less recognition of the more diffuse, complex, or covert technologies for monitoring, accessing, and repurposing their personal data by second and third parties. Researching personal data practices is still a nascent field of research, particularly from a sociological perspective. Further enquiries into this topic could explore such aspects as: What are the differences in data practices that emerge between different social groups and institutions? How do other contexts shape data meanings and practices (spatial location, culture, history)? What are the power relations that support or restrict data practices?...\" (Lupton, 2017)"
  },
  {
    "label": "Transparency and Trust",
    "type": "Class",
    "description": "One of the ethical parameters that insists that all stakeholders should be able to understand and trust the internal processes of the system.",
    "provocation": "Is a human-machine relation based on transparency or trust?",
    "references": "\"...Whoever connects transparency only with corruption and the freedom of information has failed to recognize its scope. Transparency is a systemic compulsion gripping all social processes and subjecting them to a deep-reaching change. Today’s social system submits all its processes to the demand for transparency in order to operationalize and accelerate them. Pressure for acceleration represents the corollary of dismantling negativity. Communication reaches its maximum velocity where like responds to like, when a chain reaction of likeness occurs. The negativity of alterity and foreignness—in other words, the resistance of the Other—disturbs and delays the smooth communication of the Same. Transparency stabilizes and speeds the system by eliminating the Other and the Alien...Clearly the human soul requires realms where it can be at home without the gaze of the Other. It claims a certain impermeability. Total illumination would scorch it and cause a particular kind of\nspiritual burnout. Only machines are transparent... Trust is only possible in a state between knowing and not knowing. Trust means establishing a positive relationship with the Other, even in ignorance. It makes actions possible despite one’s lack of knowledge. If I know everything in advance, there is no need for trust\". Trust is only possible in a state between knowing and notknowing. Trust means establishing a positive relationship with the Other, even in ignorance. It makes actions possible despite one’s lack of knowledge. If I know everything in advance, there is no need for trust...\" (Han & Butler, 2015)"
  },
  {
    "label": "Transparency As Performativity",
    "type": "Class",
    "description": "Reinterpretation of transparency that foregrounds the wider frame and contextual social factors that determine the meaning and effect of transparency practices.",
    "provocation": "What does the work of transparency do?",
    "references": "There's a need to distinguish between \"transparency as a verfiability and transparency as performativity\".\n\n“...The first approach understands transparency as the disclosure of information. Transparency as outlined in Section 2, with regard to its understanding in the GDPR and in the tradition of informed consent, aligns with this approach. Following this understanding, organizations and institutions are transparent when they release information about their internal practices, for example, their data collection and data analysis. In the context of AI, an example would be a shopping mall that announces at the entrance and on its website whether it uses facial recognition technology to track shoppers, rather than keeping this information hidden (Rieger, 2018). The second approach, however, looks at the tensions, struggles, and discourses inherent in transparency projects, and at unintended consequences and downsides of transparency. Following this approach, transparency should be understood more holistically, including the socio-material and ritualistic practices of organizations when they ‘‘perform’’ transparency. The performativity perspective understands transparency practices as social and organizational phenomena whose meaning goes substantially beyond the information conveyed. Similarly, technology compa nies such as Facebook or Google employ strong narra tives of openness, connectedness, and sharing on the user side while being highly secretive themselves (Van Dijck, 2013).\n\n“In the information-based approach, the user is con ceptualized as an independent actor, who makes autonomous decisions on the basis of information made available to them through transparency. By contrast, the performativity account sees contextual social factors as considerably determining the meaning of transparency practices. We propose to bring insights from both perspectives together in a relational approach to transparency that draws on the concept of trustworthiness, where transparency is understood with regard to its relational function, as a signal of trustworthiness and willingness to be accountable to those affected by one’s actions or products.” (Felzmann et al., 2019). \"...Such rethinking requires acknowledging that transparency—the capacity to explain and understand decisions with reference to a‘universal’standard of rationality—is not the only basis for ethical action.Constructing common ground by enabling the possibility to arrive atshared understanding is still needed, but more often than not ethicalaction will need to start and be made in the conditions of opacity.That is to say, imperfect communication or even incommunicabilitybetween humans and algorithmic systems, humans and otherhumans, humans and their sociopolitical context. Starting fromopacity means that instead of aiming only for perfect understand-ability and transparency as safeguards for ethical action, one shouldespouse grounding ethics instead in situated, engaged and account-able action...\" (Smith et al., 2023)."
  },
  {
    "label": "Type of Funding",
    "type": "Class",
    "description": "Different ways in which projects, ideas, and AI systesm are financed.",
    "provocation": "How does funding determine various socio-technical relations? A cursory set concerns:  data ownership, copyright, wages, design of artificial intelligence, organisational structure, political agenda etc.",
    "references": "\"...Against a backdrop of declining public investment in university research and a growth in the volume of applicants for funding, academics inevitably face the dilemma of whether or not to alter their research plans so as to fit with government and funders’ priorities. The introduction of ‘impact’ as a significant criterion of research assessment and proposal evaluation has added yet another policy-driven, external requirement that academics are under pressure to meet. We have seen the number and range of different strategies that academics employ in order to navigate their way through this complex environment and still be able to conduct the research that is important to them, namely that which they feel is intrinsically worthwhile. Yet, inevitably, the priorities of government and funders are having some influence on the research that academics undertake. Furthermore, the impact agenda now means that academics are also having to undertake different\nkinds of research activities...\" (Grove, 2017)."
  },
  {
    "label": "Type of Organization",
    "type": "Class",
    "description": "Different kinds of organizations.",
    "provocation": "How do the social relations of employment—salaries, levels of hierarchy, decision-making channels, and work pressure—influence the design?",
    "references": "\"...It might be worthwhile to consider \"design of technological systems in relation to specific situations of actual people in real work situations\" (Balka, 1997). \"A common limitation of popular socio-technical approaches …is that these approaches tended to take technology as given, and consequently focused on issues such as soft-ware improvement rather than on the more contested issues, such as wat is defined as a socio/organizational problem\"It might be worthwhile to consider \"design of technological systems in relation to specific situations of actual people in real work situations...\" (Balka, 1997)."
  },
  {
    "label": "Unbanked",
    "type": "Class",
    "description": "A population defined by their lack of legible trace within any formalized mode of credit practice.",
    "provocation": "How does credit scoring produce unbanked as creditworthy and how does it  separate those that might profitably carry credit from those who cannot?",
    "references": "\"...unbanked is itself a category that is produced and made real in particular kinds of ways. Not just a self-evident category or a label for some already existing problem or pathology, the unbanked is a method of social sorting key to the ways in which the economic lives of precarious populations are ‘made up’ and rendered governable...One site that is crucial to the genealogy of the unbanked is the practice of alternative credit scoring. A series of experiments now proliferate in the use of alternative sources of data in the formalization of credit scores for those without credit records or files. These alternative data include local public records, social networking patterns, academic achievement records, mobile phone usage, non-financial payment histories, and, increasingly, psychometric test results. These experiments, I argue, are an important setting key to the ways in which the ‘unbanked’ is constituted as a category of knowledge and intervention...Alternative credit scores do not assess credit in relation to individualized traits directly observed, but in relation to quantifiable and regular patterns gleaned from the assessment of increasingly large sets of big data. This can result in low credit scores not well coordinated to particular circumstances or individualized conditions. These problems are exacerbated because scores based on machine learning and big data frequently entail a codified rigidity. Some data streamed into algorithms are inaccurate or imprecise. Because algorithms are fed from increasingly large and diverse data points they are vulnerable to errors and inconsistencies. Moreover, data that are used in the creation of alternative credit scores are proprietary and, as a result, are insulated from scrutiny and transparency. Alternative credit data ‘tools are non-transparent and rely on inaccurate data collected form numerous sources, making it difficult for consumers to verify or challenge unfair decisions’ (Hurley and Adebayo, 2016: 166)... \"(Aitken, 2017)\""
  },
  {
    "label": "Unemployed",
    "type": "Class",
    "description": "Individuals who are not currently employed.",
    "provocation": "How does the system frame the problem of unemployment and employability and how this framing is enacted by its socio-technical specification?",
    "references": "\"...As of 2020, the Public Employment Service Austria (AMS) makes use of algorithmic profiling of job seekers to increase the efficiency of its counseling process and the effectiveness of active labor market programs. Based on a statistical model of job seekers' prospects on the labor market, the system—that has become known as the AMS algorithm—is designed to classify clients of the AMS into three categories: those with high chances to find a job within half a year, those with mediocre prospects on the job market, and those clients with a bad outlook of employment in the next 2 years....After a test phase in 2019 the system will be introduced nation-wide in 2020. The project—commonly referred to as the “AMS algorithm”—has created a heated public debate. Criticism pointed to a lack of transparency, missing possibilities to remedy decisions for AMS customers, the use of sensitive information, possible unintended consequences, such as discrimination, misinterpretation and stigmatization, as well as its potential for reinforcing and amplifying inequality on the labor market. In particular, the inclusion of gender as a variable raised public concerns about gender discrimination. The illustrative model that is part of the documentation lists “female” as being detrimental to the chances of labor market integration reducing the total score of this group (−0.14). Additionally, the variable “obligations of care” was noted to only apply to women...On a conceptual level, we ask how the (semi-)automated profiling of job seekers frames the problem of unemployment and employability and how this framing is enacted by the socio-technical specification of the system. With regard to the technical specification of the system, we ask what data and personal attributes of job seekers are considered in the statistical model, which ones are neglected and what kind of biases this may entail. What performance measures are used to document the reliability of the system and what do they imply? The system's implementation within the organizational practices of the AMS has extensive social implications. What does it imply for the distribution of agency and accountability between the system and the case workers? How have issues of transparency and accountability of the system been handled during the development and test phases?...\" (Allhutter et al., 2020)"
  },
  {
    "label": "Unintended Consequence",
    "type": "Class",
    "description": "Those effects of an AI system which were unintended but could have been anticipated in the design, deployment or use-case of the system.",
    "provocation": "Could unintended consequences be accounted for in the design of the AI system?",
    "references": "“...Unintended consequences” has come to mean unforeseen side effects, the study of which is often called the raison d’être of social science. However, this conceptual conflation has rendered invisible another category of outcomes, namely unintended but anticipated consequences. This category does not fit the classic dichotomy between “design” and “spontaneous growth” because unintended but anticipated consequences are neither designed nor generated spontaneously; they are better characterized as “permitted outcomes.”What makes reformers appear naïve, I would add, is the habit of using uanintended as a synonym for unanticipated, whereas in reality reformers must often make “difficult” choices—difficult precisely because they foresee unwelcome effects. Conflating “unintended” and “unanticipated” obscures this...\"...Why, then, does this conflation remain so pervasive? One reason is that all parties involved in the analysis of unintended consequences benefit from it. Rulers and policy reformers also benefit from conflating “unintended” and “unanticipated” consequences because it helps them to shed responsibility and avoid discussion about hurtful choices. The disentangling of unintended and unanticipated consequences foregrounds questions of justification and responsibility...\" (de Zwart, 2015)"
  },
  {
    "label": "Union",
    "type": "Class",
    "description": "An organization of workers that works towards maintaining or improving the working conditions of their members.",
    "provocation": "What's the role of trade unions concerning the design and deployment of AI systems?",
    "references": "\"\"\"...Even though trade unions acknowledge that transparencyvand accountability could solve problems arising from automation in the workplace, starting to create specific hands-on tools would go a long way to support\nworker representatives. First hands-on guides and\nlegislative advances exist. But mostly the activities of\ntrade unions still center around formulating ethical\nguidelines and principles and learning about the\nimpact of automation in the world of work. It is now\nthe time to focus more heavily on the implementation of such guidelines.\nThese findings demonstrate that trade unions need\nto shift focus to a more practice-oriented approach...\"\"(Algorithm Watch, 2023)\""
  },
  {
    "label": "University and College",
    "type": "Class",
    "description": "A type of education consumer that is involved in higher education, academic research, and authorized to grant academic degrees.",
    "provocation": "\"...Good colleges have always been fundamentally human institutions. Pardon the facile example, but Socrates and his followers didn’t have a fi tness\ncenter. Th ey didn’t have much of a campus, or dorms, or “smart” classrooms\nwith Smart Boards, clickers and docu-cams, and video capability. So far as we\nknow, they didn’t do strategic plans. Th ey didn’t even have books, printed or\nelectronic or online. What they did have, though, was each other. To make college work, that’s all you need, too...\" (Chambliss & Takacs, 2014)",
    "references": "(To be updated)"
  },
  {
    "label": "User",
    "type": "Class",
    "description": "An individual or a group that uses the AI system.",
    "provocation": "What kind of a relationship does the user form with the AI system---dependent, support, critical, playful etc.?",
    "references": "...The concern vis-a-vis user \"relates directly to issues of power between those who shape a system and those affected by it... In particular, there is an interest in who has–or should have–the decision-making authority regarding a system’s development (e.g., Busuioc 2020; Coglianese and Lehr 2016; Crawford 2021; Kalluri 2020; Sloane and Moss 2019). The debate, hence, seems to invoke a moral intuition that there is something deeply problematic about how ML systems are currently developed and used within society...\" (Maas, 2022)."
  },
  {
    "label": "Utilitarianism",
    "type": "Class",
    "description": "A type of normative ethical framework that prescribes actions to be morally good if they maximize happiness for most people.",
    "provocation": "Who remains uncounted when calculating the maximum good?",
    "references": "\"...Utilitarian thinkers maintain that right actions produce the most good for those sentient entities affected by a given action. Bentham and Mill (mentioned in Sect. 2) present classic versions of the theory; although they disagree on some aspects they both specify that the good is pleasure or happiness. Another view, more popular nowadays, is that the good is preference satisfaction. It focuses on doing those actions that satisfy the preferences of the greatest number of individuals. Besides these two conceptions of the good, utilitarianism can be modified and stretched in other ways. For example, many advocates argue that the right action is the one that is expected to do the most good, not the one that actually does the most good, thus softening the epistemic worry that we cannot accurately predict all of an action’s results...\"\"(Bauer, 2020). \"\"...In doing so one can demonstrate that it is difficult to prove that the adoption of AI technologies is undertaken in a way, which mainly serves a powerful class in society. Nevertheless, analysing the culture around AI technologies with regard to the nature of law with a philosophical and sociological focus enables one to demonstrate a utilitarian and authoritarian trend in the adoption of AI technologies...\" (Hadzi, 2020)"
  },
  {
    "label": "Venture Capital Firm",
    "type": "Class",
    "description": "A type of financial intermediary that manages and invest pooled capital into high-risk, potentially high-reward projects by buying equity or equity-linked stakes in the firm.",
    "provocation": "Is there a conflict between social good and economic returns and how does that conflict inform the design of the AI system?",
    "references": "\"...Because VCs invest on a portfolio basis they may not be involved in the daily operation of a single venture due to constraints on resources. Instead, many VCs set milestones for the entrepreneur to meet. They then stage their capital investment and conduct the next round of investment only if the predetermined milestone is met by the entrepreneur. If the entrepreneur does not successfully lead the venture to achieve a milestone, VCs oftentimes decline the next round of funding request or even replace the current entrepreneur with another one. VCs’ primary goal is to maximizing economic returns from the entire portfolio...\" (Hsu et al., 2014)."
  },
  {
    "label": "Virtue Ethic",
    "type": "Class",
    "description": "A type of normative ethics that gives centrality to virtues or traits that are considered morally good. According to this framework, an action is ethical if it aligns with habits that are virtuous or morally good.",
    "provocation": "Can the morality of human agents be reduced to patterns in their moral behavioral data in the same way in which visual patterns compose an image?",
    "references": "\"...H&M (2016, 2017) develop a model for a virtuous AMA, with the goal of replicating “the moral behavior of human agents” (H&M 2017: 125). Towards that end, H&M broadly apply virtue theory.Focusing on the virtue theory developed by Aristotle in Nicomachean Ethics, several core features stand out. One is that humans learn moral behavior from their social environments. We become good (i.e., just or virtuous) by doing good things. Another core feature is that virtues are psychological dispositional traits, features not always manifest in the agent’s behavior, which can be triggered under appropriate conditions. For example, being courageous does not mean always doing courageous things, but acting courageously when necessary. Different situations, with agents at different levels of moral development, may require different actions (hence, virtue theory is a brand of moral particularism). A third core feature is that virtuous actions occupy a mean between two extremes: the courageous agent acts neither cowardly nor rashly, but exhibits context-sensitive moderation. H&M emphasize pattern recognition and situational learning from moral examples—i.e., machine learning applied to ethics—to build up a set of dispositional states which underpin virtuous behavior (or something approximating that). On their idealized version of a virtuous AMA, the artificial agent can adapt to new situations and make ethical decisions without appeal to rules or duties. The emphasis is on developing a morally habituated AMA that possesses virtuous dispositional traits akin to moral virtues...\"(Bauer, 2020). \n\n\"...As some virtue ethicists insist (Nussbaum, Annas, i.a.), a moral judgment is closer to classification of perceptions, than to reasoning from general to particular. The virtuous person makes right moral judgments on a case-by-case basis: the person of principle is prone to make bad moral decisions because she has the “tendency not to look hard enough at the details of the case before one.” (Gleeson, 2007, p. 369) For the moral particularist, this entails that moral judgments need a form of moral sensibility to the context and content of each case. (Dancy, 2006) A moral\nexpert “just sees” which features of a case are morally relevant and what action is needed. The agent cannot or does not need to follow a moral principle. The moral expert develops a perceptual-like moral competence by exploring a set of “prototypes, clearest cases, or best\nexamples.” (Dancy, 1999, p. 70) The process of categorization of moral cases is similar to the perception in which the trained observer is able to classify and categorize new information...\" (Howard & Muntean, 2016)"
  },
  {
    "label": "Weakening of Democracy",
    "type": "Class",
    "description": "Refers to a scenario where AI systems weaken democratic norms such as a equality, distribution of power, freedom of expression, autonomy etc.",
    "provocation": "What is democracy? Is/was the society democratic in first place?",
    "references": "\"Algorithmic communications pose a number of challenges to democracy. The three phenomena of filtering, hypernudging, and microtargeting can have the effect of polarizing an electorate and thus undermine the deliberative potential of a democratic society. Algorithms can spread fake news throughout society, undermining the epistemic potential that broad participation in democracy is meant to offer. They can pose a threat to political equality in that some people may have the means to make use of algorithmic communications and the sophistication to be immune from attempts at manipulation while other people are vulnerable to manipulation by those who use these means.\" (Christiano, 2022)."
  },
  {
    "label": "What For",
    "type": "Class",
    "description": "A question situated in the ethical-political practice of care that critically evaluates the reasons for caring without assuming a moral stance.",
    "provocation": "Do care practices built into the AI system provoke political and ethical imagination in the present?",
    "references": "\"...The question, then, is not ‘how can we care more?’ but instead to ask what happens to our work when we pay attention to moments where the question of ‘how to care?’ is insistent but not easily answerable. In this way, we use care as an analytic or provocation, more than a predetermined set of affective practices...” (Bellacasa, 2017).\""
  },
  {
    "label": "Who Cares",
    "type": "Class",
    "description": "A question situated in the ethical-political practice of care that critically evaluates the body that is represented as being in the position of care.",
    "provocation": "Who cares about whom in the design of an AI system?",
    "references": "\"...The open question How to care? (which I asked in chapter 1 as a premise for specific discussions of care) grounds care ethics in situation. This wondering remains a critically troubling question that entails unpacking what is actually done under the name of care, whatever good the intentions. Care is not only political, messy, and dirty; it is a trap for many and not less in technoscience. But asking how to care is an open wonder about the ethicopolitical significance of doings of care as immanent obligation. So while a critical stance can bring attention to such matters as who cares for whom, to what forms of care are prioritized at the expenses of others, a politics of speculative thinking also is a commitment to seek what other worlds could be in the making through caring while staying with the trouble of our own complicities and implications...\" (Bellacasa, 2017)"
  },
  {
    "label": "Why Care",
    "type": "Class",
    "description": "A question situated in the ethical-political practice of care that critically evaluates the totalizing and normative effects of caring practices in favour of caring as provocation \"that remains speculative by not letting a situation or a position—or even the acute awareness of pervasive dominations—define in advance what is or could be\".",
    "provocation": "Why do the donors or the developers care about a particular problem?",
    "references": "\"Ontologies and identities are affected by collective politics and positionalities that constantly have to confront and put into question the boundaries and cuts given in existing worlds (e.g., the takenfor-granted “woman”). This way of thinking about creating other relations, other possibilities of existence—namely, other beings—is linked to concerns for the consequences of relations. What and how we enter in relations affects positions and relational ecologies. No longing here for fixed realities that could police the outcomes of encounters by confirming correspondence to preexisting “orders.” A relational way of thinking, which I call here “thinking-with,” creates new patterns out of previous multiplicities, intervening by adding layers of meaning rather than merely deconstructing or conforming to ready-made categories\" (Bellacasa, 2017)."
  },
  {
    "label": "Worker",
    "type": "Class",
    "description": "Any individual engaged in paid work.",
    "provocation": "How does the AI design reshape worker's relationship with work/labour?",
    "references": "The issue concerning AI in the workplace is complicated and contested. It involves more practical concerns vis-à-vis surveillance, micromanagement, data work, and value extraction to more speculative concerns vis-à-vis a future of work and experience of work. The core premise of relational ethics becomes even more relevant here as the answer vis-a-vis what is ethical in the context of AI and work is not straightforward. It remains to be seen how AI will disrupt the status quo built into the wage-labour relationship and how does it reshape our understanding of what is meaningful work and subsequently what it mean to have a good life."
  },
  {
    "label": "Ask",
    "type": "Relation",
    "description": "",
    "provocation": "",
    "references": ""
  },
  {
    "label": "BasedOn",
    "type": "Relation",
    "description": "",
    "provocation": "",
    "references": ""
  },
  {
    "label": "Can",
    "type": "Relation",
    "description": "",
    "provocation": "",
    "references": ""
  },
  {
    "label": "CanCause",
    "type": "Relation",
    "description": "",
    "provocation": "",
    "references": ""
  },
  {
    "label": "CanGenerate",
    "type": "Relation",
    "description": "",
    "provocation": "",
    "references": ""
  },
  {
    "label": "CriticalOf",
    "type": "Relation",
    "description": "",
    "provocation": "",
    "references": ""
  },
  {
    "label": "CutAcross",
    "type": "Relation",
    "description": "",
    "provocation": "",
    "references": ""
  },
  {
    "label": "ExperimentWith",
    "type": "Relation",
    "description": "",
    "provocation": "",
    "references": ""
  },
  {
    "label": "FocusOn",
    "type": "Relation",
    "description": "",
    "provocation": "",
    "references": ""
  },
  {
    "label": "GiveFunding",
    "type": "Relation",
    "description": "",
    "provocation": "",
    "references": ""
  },
  {
    "label": "Has",
    "type": "Relation",
    "description": "",
    "provocation": "",
    "references": ""
  },
  {
    "label": "HasActor",
    "type": "Relation",
    "description": "",
    "provocation": "",
    "references": ""
  },
  {
    "label": "HasAffordance",
    "type": "Relation",
    "description": "",
    "provocation": "",
    "references": ""
  },
  {
    "label": "HasApproach",
    "type": "Relation",
    "description": "",
    "provocation": "",
    "references": ""
  },
  {
    "label": "HasDomain",
    "type": "Relation",
    "description": "",
    "provocation": "",
    "references": ""
  },
  {
    "label": "HasExpectation",
    "type": "Relation",
    "description": "",
    "provocation": "",
    "references": ""
  },
  {
    "label": "HasImpact",
    "type": "Relation",
    "description": "",
    "provocation": "",
    "references": ""
  },
  {
    "label": "HasType",
    "type": "Relation",
    "description": "",
    "provocation": "",
    "references": ""
  },
  {
    "label": "InfluencedBy",
    "type": "Relation",
    "description": "",
    "provocation": "",
    "references": ""
  },
  {
    "label": "IsAbout",
    "type": "Relation",
    "description": "",
    "provocation": "",
    "references": ""
  },
  {
    "label": "Manipulate",
    "type": "Relation",
    "description": "",
    "provocation": "",
    "references": ""
  },
  {
    "label": "Redefine",
    "type": "Relation",
    "description": "",
    "provocation": "",
    "references": ""
  },
  {
    "label": "StudyOf",
    "type": "Relation",
    "description": "",
    "provocation": "",
    "references": ""
  },
  {
    "label": "UsedIn",
    "type": "Relation",
    "description": "",
    "provocation": "",
    "references": ""
  },
  {
    "label": "assembles",
    "type": "Relation",
    "description": "",
    "provocation": "",
    "references": ""
  }
]
